{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjWvnaQUrZmD"
      },
      "source": [
        "# Emotion classification using the RAVDESS dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldtHMhuLrewK"
      },
      "source": [
        "The RAVDESS contains 7356 files. Ratings were provided by 247 individuals.\n",
        "\n",
        "***Description***\n",
        "\n",
        "The dataset contains the complete set of 7356 RAVDESS files (total size: 24.8 GB). Each of the 24 actors consists of two modality formats: Audio-only (16bit, 48kHz .wav), Audio-Video (720p H.264, AAC 48kHz, .mp4).\n",
        "\n",
        "***File naming convention***\n",
        "\n",
        "Each of the 7356 RAVDESS files has a unique filename. The filename consists of a 7-part numerical identifier (e.g., 02-01-06-01-02-01-12.mp4). These identifiers define the stimulus characteristics:\n",
        "\n",
        "***Filename identifiers***\n",
        "\n",
        "- Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "- Vocal channel (01 = speech, 02 = song).\n",
        "- Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "- Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the ‘neutral’ emotion.\n",
        "- Statement (01 = “Kids are talking by the door”, 02 = “Dogs are sitting by the door”).\n",
        "- Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "- Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
        "\n",
        "Filename example: 02-01-06-01-02-01-12.mp4 \n",
        "\n",
        "- Video-only (02)\n",
        "- Speech (01)\n",
        "- Fearful (06)\n",
        "- Normal intensity (01)\n",
        "- Statement “dogs” (02)\n",
        "- 1st Repetition (01)\n",
        "- 12th Actor (12)\n",
        "- Female, as the actor ID number is even."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Packages**"
      ],
      "metadata": {
        "id": "lcTSHVjGEPNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "Syta_ZC9Ew20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "from librosa import display"
      ],
      "metadata": {
        "id": "-morl15ZELJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment"
      ],
      "metadata": {
        "id": "23hzNTAQEtbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "j7byNtQ9E6ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Connect to Drive**"
      ],
      "metadata": {
        "id": "O143-b3vDkJZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-o2JI49WBAe",
        "outputId": "93bb671a-a384-4f3e-9732-f82be024e5ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **One File**"
      ],
      "metadata": {
        "id": "XiE4aY-DFU6Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxI4xzngdS-e"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Emotion/features/Actor_05/03-02-06-01-02-02-05.wav'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rawsound = AudioSegment.from_file(path)\n",
        "data, sampling_rate = librosa.load(path, sr = None)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "librosa.display.waveplot(data, sampling_rate)\n",
        "plt.title('Initial audio')\n",
        "\n",
        "rawsound"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "5noc2l90EFJl",
        "outputId": "fce7607e-8542-428a-d22f-569ac635c1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pydub.audio_segment.AudioSegment at 0x7f13f7f84410>"
            ],
            "text/html": [
              "\n",
              "                    <audio controls>\n",
              "                        <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\"/>\n",
              "                        Your browser does not support the audio element.\n",
              "                    </audio>\n",
              "                  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCtNuVWlr5jL"
      },
      "source": [
        "# **Load all files**\n",
        "\n",
        "We will create our numpy array extracting Mel-frequency cepstral coefficients (MFCCs), while the classes to predict will be extracted from the name of the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKvuF--gd6F-",
        "outputId": "05b538a3-e7e1-4ab0-af40-0e7c060232d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data loaded. Loading time: 334.5253093242645 seconds ---\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "path = '/content/drive/MyDrive/Emotion/features'\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLSggnF7kKY1"
      },
      "outputs": [],
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzvBRTJIlIE9",
        "outputId": "f51a43fe-683d-49a5-c9c2-7579967fbd6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5252, 40), (5252,))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOutQiAlCjOY"
      },
      "outputs": [],
      "source": [
        "# Saving joblib files to not load them again with the loop above\n",
        "\n",
        "import joblib\n",
        "\n",
        "X_name = 'X.joblib'\n",
        "y_name = 'y.joblib'\n",
        "save_dir = '/content/drive/MyDrive/Emotion'\n",
        "\n",
        "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIoFdycUXMxA"
      },
      "outputs": [],
      "source": [
        "# Loading saved models\n",
        "import joblib\n",
        "\n",
        "X = joblib.load('/content/drive/MyDrive/Emotion/X.joblib')\n",
        "y = joblib.load('/content/drive/MyDrive/Emotion/y.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9eqMHV3S8i6"
      },
      "source": [
        "# **Neural network CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-QscoyMxQtn"
      },
      "source": [
        "Let's build our neural network!\n",
        "\n",
        "To do so, we need to expand the dimensions of our array, adding a third one using the numpy \"expand_dims\" feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-Xgb5NslTBO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmm4tnALH2zx",
        "outputId": "c41de459-38d4-43e4-9ecd-6a888558a40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3518, 40), (1734, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4i187-Pe-w5"
      },
      "outputs": [],
      "source": [
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnvoCRX1gQCh",
        "outputId": "048d9ab3-5549-4a8c-c808-e743876084a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3518, 40, 1), (1734, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "x_traincnn.shape, x_testcnn.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Lroa8wsMIDob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZOGIpuefCd3"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 5, padding='same', input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(8))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = RMSprop(learning_rate=0.00005, rho=0.9, epsilon=None, decay=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LphftMIZzUvz"
      },
      "source": [
        "With *model.summary* we can see a recap of what we have build:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIWPB4Zgfic7",
        "outputId": "25c2ae25-5340-4f16-e1cf-78e1132df2d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (None, 40, 128)           768       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 5, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 5, 128)            82048     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 5, 128)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 5, 128)            0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 640)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 5128      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,944\n",
            "Trainable params: 87,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qQSBeBhzcLu"
      },
      "source": [
        "Now we can compile and fit our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNI1znbsfpTx"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktdF-nJKfq6F",
        "outputId": "64d4f601-bca1-415e-9526-7b0c8ca8a5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "220/220 [==============================] - 13s 6ms/step - loss: 5.1950 - accuracy: 0.2047 - val_loss: 1.7582 - val_accuracy: 0.3783\n",
            "Epoch 2/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 3.4842 - accuracy: 0.2959 - val_loss: 1.5466 - val_accuracy: 0.4769\n",
            "Epoch 3/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 2.5911 - accuracy: 0.3758 - val_loss: 1.4288 - val_accuracy: 0.4804\n",
            "Epoch 4/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 2.0755 - accuracy: 0.4210 - val_loss: 1.2240 - val_accuracy: 0.5681\n",
            "Epoch 5/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 1.7442 - accuracy: 0.4835 - val_loss: 1.1717 - val_accuracy: 0.6188\n",
            "Epoch 6/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 1.5380 - accuracy: 0.4977 - val_loss: 1.2157 - val_accuracy: 0.5467\n",
            "Epoch 7/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 1.4090 - accuracy: 0.5296 - val_loss: 1.1587 - val_accuracy: 0.6165\n",
            "Epoch 8/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 1.3190 - accuracy: 0.5597 - val_loss: 1.1222 - val_accuracy: 0.6003\n",
            "Epoch 9/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 1.2488 - accuracy: 0.5733 - val_loss: 1.0859 - val_accuracy: 0.6194\n",
            "Epoch 10/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 1.1945 - accuracy: 0.5881 - val_loss: 1.0355 - val_accuracy: 0.6580\n",
            "Epoch 11/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 1.1572 - accuracy: 0.5964 - val_loss: 1.0252 - val_accuracy: 0.6459\n",
            "Epoch 12/1000\n",
            "220/220 [==============================] - 1s 7ms/step - loss: 1.1155 - accuracy: 0.6151 - val_loss: 1.0257 - val_accuracy: 0.6638\n",
            "Epoch 13/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 1.0876 - accuracy: 0.6188 - val_loss: 1.0123 - val_accuracy: 0.6522\n",
            "Epoch 14/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 1.0502 - accuracy: 0.6427 - val_loss: 0.9591 - val_accuracy: 0.6655\n",
            "Epoch 15/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 1.0173 - accuracy: 0.6433 - val_loss: 0.9230 - val_accuracy: 0.6840\n",
            "Epoch 16/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.9988 - accuracy: 0.6509 - val_loss: 0.9156 - val_accuracy: 0.6776\n",
            "Epoch 17/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.9728 - accuracy: 0.6487 - val_loss: 0.9025 - val_accuracy: 0.6897\n",
            "Epoch 18/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.9573 - accuracy: 0.6555 - val_loss: 0.8928 - val_accuracy: 0.6822\n",
            "Epoch 19/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.9320 - accuracy: 0.6663 - val_loss: 0.8746 - val_accuracy: 0.6984\n",
            "Epoch 20/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.9178 - accuracy: 0.6688 - val_loss: 0.8763 - val_accuracy: 0.6909\n",
            "Epoch 21/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.9095 - accuracy: 0.6717 - val_loss: 0.8535 - val_accuracy: 0.7001\n",
            "Epoch 22/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.8938 - accuracy: 0.6853 - val_loss: 0.8464 - val_accuracy: 0.6880\n",
            "Epoch 23/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.8644 - accuracy: 0.6856 - val_loss: 0.8437 - val_accuracy: 0.6984\n",
            "Epoch 24/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.8528 - accuracy: 0.6995 - val_loss: 0.8273 - val_accuracy: 0.6978\n",
            "Epoch 25/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.8491 - accuracy: 0.6944 - val_loss: 0.8333 - val_accuracy: 0.7024\n",
            "Epoch 26/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.8444 - accuracy: 0.6958 - val_loss: 0.8219 - val_accuracy: 0.7134\n",
            "Epoch 27/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.8308 - accuracy: 0.6973 - val_loss: 0.8047 - val_accuracy: 0.7163\n",
            "Epoch 28/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.8181 - accuracy: 0.7103 - val_loss: 0.7968 - val_accuracy: 0.7215\n",
            "Epoch 29/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.8013 - accuracy: 0.7103 - val_loss: 0.8128 - val_accuracy: 0.7007\n",
            "Epoch 30/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.7862 - accuracy: 0.7169 - val_loss: 0.7853 - val_accuracy: 0.7151\n",
            "Epoch 31/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.7814 - accuracy: 0.7189 - val_loss: 0.7755 - val_accuracy: 0.7249\n",
            "Epoch 32/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.7922 - accuracy: 0.7157 - val_loss: 0.7657 - val_accuracy: 0.7191\n",
            "Epoch 33/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.7710 - accuracy: 0.7223 - val_loss: 0.7598 - val_accuracy: 0.7226\n",
            "Epoch 34/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.7596 - accuracy: 0.7291 - val_loss: 0.7828 - val_accuracy: 0.7082\n",
            "Epoch 35/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.7483 - accuracy: 0.7291 - val_loss: 0.7511 - val_accuracy: 0.7376\n",
            "Epoch 36/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.7424 - accuracy: 0.7274 - val_loss: 0.7594 - val_accuracy: 0.7278\n",
            "Epoch 37/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.7392 - accuracy: 0.7265 - val_loss: 0.7433 - val_accuracy: 0.7197\n",
            "Epoch 38/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.7349 - accuracy: 0.7337 - val_loss: 0.7509 - val_accuracy: 0.7122\n",
            "Epoch 39/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.7379 - accuracy: 0.7314 - val_loss: 0.7546 - val_accuracy: 0.7393\n",
            "Epoch 40/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.7118 - accuracy: 0.7342 - val_loss: 0.7164 - val_accuracy: 0.7416\n",
            "Epoch 41/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.7180 - accuracy: 0.7388 - val_loss: 0.7264 - val_accuracy: 0.7272\n",
            "Epoch 42/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6971 - accuracy: 0.7538 - val_loss: 0.7234 - val_accuracy: 0.7284\n",
            "Epoch 43/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.7046 - accuracy: 0.7374 - val_loss: 0.7120 - val_accuracy: 0.7393\n",
            "Epoch 44/1000\n",
            "220/220 [==============================] - 2s 7ms/step - loss: 0.6924 - accuracy: 0.7464 - val_loss: 0.7045 - val_accuracy: 0.7474\n",
            "Epoch 45/1000\n",
            "220/220 [==============================] - 2s 7ms/step - loss: 0.6896 - accuracy: 0.7487 - val_loss: 0.7048 - val_accuracy: 0.7480\n",
            "Epoch 46/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.6843 - accuracy: 0.7487 - val_loss: 0.7090 - val_accuracy: 0.7393\n",
            "Epoch 47/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6799 - accuracy: 0.7527 - val_loss: 0.7198 - val_accuracy: 0.7255\n",
            "Epoch 48/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.6747 - accuracy: 0.7553 - val_loss: 0.6981 - val_accuracy: 0.7520\n",
            "Epoch 49/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6708 - accuracy: 0.7558 - val_loss: 0.6998 - val_accuracy: 0.7399\n",
            "Epoch 50/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.6654 - accuracy: 0.7598 - val_loss: 0.6825 - val_accuracy: 0.7624\n",
            "Epoch 51/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6713 - accuracy: 0.7524 - val_loss: 0.6802 - val_accuracy: 0.7468\n",
            "Epoch 52/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6670 - accuracy: 0.7598 - val_loss: 0.6971 - val_accuracy: 0.7382\n",
            "Epoch 53/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.6575 - accuracy: 0.7587 - val_loss: 0.6841 - val_accuracy: 0.7514\n",
            "Epoch 54/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.6400 - accuracy: 0.7641 - val_loss: 0.6856 - val_accuracy: 0.7503\n",
            "Epoch 55/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6510 - accuracy: 0.7615 - val_loss: 0.6710 - val_accuracy: 0.7561\n",
            "Epoch 56/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6448 - accuracy: 0.7661 - val_loss: 0.6713 - val_accuracy: 0.7520\n",
            "Epoch 57/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6233 - accuracy: 0.7749 - val_loss: 0.7009 - val_accuracy: 0.7439\n",
            "Epoch 58/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6287 - accuracy: 0.7743 - val_loss: 0.6721 - val_accuracy: 0.7566\n",
            "Epoch 59/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6282 - accuracy: 0.7644 - val_loss: 0.6616 - val_accuracy: 0.7624\n",
            "Epoch 60/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6234 - accuracy: 0.7681 - val_loss: 0.6559 - val_accuracy: 0.7589\n",
            "Epoch 61/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6167 - accuracy: 0.7752 - val_loss: 0.6606 - val_accuracy: 0.7549\n",
            "Epoch 62/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.6240 - accuracy: 0.7754 - val_loss: 0.6514 - val_accuracy: 0.7624\n",
            "Epoch 63/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6167 - accuracy: 0.7695 - val_loss: 0.6622 - val_accuracy: 0.7584\n",
            "Epoch 64/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6109 - accuracy: 0.7800 - val_loss: 0.6657 - val_accuracy: 0.7636\n",
            "Epoch 65/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6089 - accuracy: 0.7760 - val_loss: 0.6453 - val_accuracy: 0.7705\n",
            "Epoch 66/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.6012 - accuracy: 0.7783 - val_loss: 0.6506 - val_accuracy: 0.7584\n",
            "Epoch 67/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.7800 - val_loss: 0.6405 - val_accuracy: 0.7659\n",
            "Epoch 68/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.6007 - accuracy: 0.7791 - val_loss: 0.6622 - val_accuracy: 0.7566\n",
            "Epoch 69/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5897 - accuracy: 0.7840 - val_loss: 0.6284 - val_accuracy: 0.7722\n",
            "Epoch 70/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5927 - accuracy: 0.7808 - val_loss: 0.6348 - val_accuracy: 0.7739\n",
            "Epoch 71/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5964 - accuracy: 0.7769 - val_loss: 0.6515 - val_accuracy: 0.7589\n",
            "Epoch 72/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5846 - accuracy: 0.7919 - val_loss: 0.6367 - val_accuracy: 0.7682\n",
            "Epoch 73/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5890 - accuracy: 0.7808 - val_loss: 0.6310 - val_accuracy: 0.7710\n",
            "Epoch 74/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5840 - accuracy: 0.7891 - val_loss: 0.6346 - val_accuracy: 0.7687\n",
            "Epoch 75/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5852 - accuracy: 0.7825 - val_loss: 0.6179 - val_accuracy: 0.7762\n",
            "Epoch 76/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5769 - accuracy: 0.7908 - val_loss: 0.6236 - val_accuracy: 0.7693\n",
            "Epoch 77/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5738 - accuracy: 0.7854 - val_loss: 0.6246 - val_accuracy: 0.7757\n",
            "Epoch 78/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5780 - accuracy: 0.7848 - val_loss: 0.6116 - val_accuracy: 0.7734\n",
            "Epoch 79/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5661 - accuracy: 0.7942 - val_loss: 0.6362 - val_accuracy: 0.7705\n",
            "Epoch 80/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5674 - accuracy: 0.7902 - val_loss: 0.6155 - val_accuracy: 0.7826\n",
            "Epoch 81/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5595 - accuracy: 0.7911 - val_loss: 0.6120 - val_accuracy: 0.7768\n",
            "Epoch 82/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5546 - accuracy: 0.7936 - val_loss: 0.6145 - val_accuracy: 0.7751\n",
            "Epoch 83/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5655 - accuracy: 0.7911 - val_loss: 0.6089 - val_accuracy: 0.7774\n",
            "Epoch 84/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5583 - accuracy: 0.7951 - val_loss: 0.6114 - val_accuracy: 0.7780\n",
            "Epoch 85/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5536 - accuracy: 0.7982 - val_loss: 0.6254 - val_accuracy: 0.7630\n",
            "Epoch 86/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5451 - accuracy: 0.8056 - val_loss: 0.6111 - val_accuracy: 0.7791\n",
            "Epoch 87/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.7973 - val_loss: 0.6071 - val_accuracy: 0.7734\n",
            "Epoch 88/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5496 - accuracy: 0.7936 - val_loss: 0.5989 - val_accuracy: 0.7860\n",
            "Epoch 89/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5476 - accuracy: 0.7973 - val_loss: 0.6060 - val_accuracy: 0.7780\n",
            "Epoch 90/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.8050 - val_loss: 0.6208 - val_accuracy: 0.7739\n",
            "Epoch 91/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5338 - accuracy: 0.8022 - val_loss: 0.6004 - val_accuracy: 0.7780\n",
            "Epoch 92/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5262 - accuracy: 0.8024 - val_loss: 0.5996 - val_accuracy: 0.7860\n",
            "Epoch 93/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.8024 - val_loss: 0.5979 - val_accuracy: 0.7809\n",
            "Epoch 94/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5292 - accuracy: 0.8090 - val_loss: 0.5896 - val_accuracy: 0.7872\n",
            "Epoch 95/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5322 - accuracy: 0.8115 - val_loss: 0.5899 - val_accuracy: 0.7837\n",
            "Epoch 96/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5247 - accuracy: 0.8076 - val_loss: 0.5884 - val_accuracy: 0.7762\n",
            "Epoch 97/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5243 - accuracy: 0.8107 - val_loss: 0.5809 - val_accuracy: 0.7907\n",
            "Epoch 98/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.8121 - val_loss: 0.6014 - val_accuracy: 0.7757\n",
            "Epoch 99/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5214 - accuracy: 0.8044 - val_loss: 0.5884 - val_accuracy: 0.7826\n",
            "Epoch 100/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5166 - accuracy: 0.8158 - val_loss: 0.5856 - val_accuracy: 0.7889\n",
            "Epoch 101/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5093 - accuracy: 0.8081 - val_loss: 0.5860 - val_accuracy: 0.7941\n",
            "Epoch 102/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5166 - accuracy: 0.8087 - val_loss: 0.5892 - val_accuracy: 0.7860\n",
            "Epoch 103/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5080 - accuracy: 0.8132 - val_loss: 0.5907 - val_accuracy: 0.7907\n",
            "Epoch 104/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.8096 - val_loss: 0.5721 - val_accuracy: 0.7884\n",
            "Epoch 105/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5127 - accuracy: 0.8144 - val_loss: 0.6100 - val_accuracy: 0.7687\n",
            "Epoch 106/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5017 - accuracy: 0.8141 - val_loss: 0.5794 - val_accuracy: 0.7837\n",
            "Epoch 107/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5079 - accuracy: 0.8127 - val_loss: 0.5908 - val_accuracy: 0.7826\n",
            "Epoch 108/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.8130 - val_loss: 0.5883 - val_accuracy: 0.7860\n",
            "Epoch 109/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.5078 - accuracy: 0.8152 - val_loss: 0.6092 - val_accuracy: 0.7710\n",
            "Epoch 110/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5076 - accuracy: 0.8155 - val_loss: 0.5828 - val_accuracy: 0.7878\n",
            "Epoch 111/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4992 - accuracy: 0.8215 - val_loss: 0.6110 - val_accuracy: 0.7768\n",
            "Epoch 112/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5023 - accuracy: 0.8167 - val_loss: 0.5751 - val_accuracy: 0.7935\n",
            "Epoch 113/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4965 - accuracy: 0.8223 - val_loss: 0.5658 - val_accuracy: 0.7993\n",
            "Epoch 114/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.8204 - val_loss: 0.5667 - val_accuracy: 0.7976\n",
            "Epoch 115/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4973 - accuracy: 0.8181 - val_loss: 0.5689 - val_accuracy: 0.7930\n",
            "Epoch 116/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.8286 - val_loss: 0.5734 - val_accuracy: 0.7901\n",
            "Epoch 117/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.8232 - val_loss: 0.5725 - val_accuracy: 0.7860\n",
            "Epoch 118/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4783 - accuracy: 0.8198 - val_loss: 0.5643 - val_accuracy: 0.7860\n",
            "Epoch 119/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4793 - accuracy: 0.8283 - val_loss: 0.5645 - val_accuracy: 0.7895\n",
            "Epoch 120/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4778 - accuracy: 0.8226 - val_loss: 0.5674 - val_accuracy: 0.7855\n",
            "Epoch 121/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4819 - accuracy: 0.8229 - val_loss: 0.5836 - val_accuracy: 0.7912\n",
            "Epoch 122/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4861 - accuracy: 0.8192 - val_loss: 0.5511 - val_accuracy: 0.8010\n",
            "Epoch 123/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.8243 - val_loss: 0.5699 - val_accuracy: 0.7935\n",
            "Epoch 124/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4757 - accuracy: 0.8212 - val_loss: 0.5673 - val_accuracy: 0.7958\n",
            "Epoch 125/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4751 - accuracy: 0.8238 - val_loss: 0.5594 - val_accuracy: 0.7993\n",
            "Epoch 126/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4736 - accuracy: 0.8266 - val_loss: 0.5758 - val_accuracy: 0.7860\n",
            "Epoch 127/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4726 - accuracy: 0.8255 - val_loss: 0.5636 - val_accuracy: 0.7958\n",
            "Epoch 128/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.8314 - val_loss: 0.5682 - val_accuracy: 0.7941\n",
            "Epoch 129/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.8263 - val_loss: 0.5533 - val_accuracy: 0.8016\n",
            "Epoch 130/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4752 - accuracy: 0.8198 - val_loss: 0.5613 - val_accuracy: 0.7970\n",
            "Epoch 131/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4634 - accuracy: 0.8297 - val_loss: 0.5497 - val_accuracy: 0.8080\n",
            "Epoch 132/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4595 - accuracy: 0.8280 - val_loss: 0.5692 - val_accuracy: 0.7814\n",
            "Epoch 133/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.8306 - val_loss: 0.5538 - val_accuracy: 0.7982\n",
            "Epoch 134/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4619 - accuracy: 0.8385 - val_loss: 0.5544 - val_accuracy: 0.8028\n",
            "Epoch 135/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4613 - accuracy: 0.8323 - val_loss: 0.5538 - val_accuracy: 0.7912\n",
            "Epoch 136/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4555 - accuracy: 0.8340 - val_loss: 0.5593 - val_accuracy: 0.7912\n",
            "Epoch 137/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4502 - accuracy: 0.8326 - val_loss: 0.5726 - val_accuracy: 0.7918\n",
            "Epoch 138/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4488 - accuracy: 0.8366 - val_loss: 0.5449 - val_accuracy: 0.8062\n",
            "Epoch 139/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4507 - accuracy: 0.8323 - val_loss: 0.5655 - val_accuracy: 0.7895\n",
            "Epoch 140/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4508 - accuracy: 0.8388 - val_loss: 0.5875 - val_accuracy: 0.7855\n",
            "Epoch 141/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4401 - accuracy: 0.8329 - val_loss: 0.5452 - val_accuracy: 0.7970\n",
            "Epoch 142/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4451 - accuracy: 0.8394 - val_loss: 0.5466 - val_accuracy: 0.8028\n",
            "Epoch 143/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4407 - accuracy: 0.8357 - val_loss: 0.5438 - val_accuracy: 0.8028\n",
            "Epoch 144/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4431 - accuracy: 0.8371 - val_loss: 0.5355 - val_accuracy: 0.8080\n",
            "Epoch 145/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4318 - accuracy: 0.8420 - val_loss: 0.5562 - val_accuracy: 0.7976\n",
            "Epoch 146/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4387 - accuracy: 0.8385 - val_loss: 0.5679 - val_accuracy: 0.7878\n",
            "Epoch 147/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4453 - accuracy: 0.8394 - val_loss: 0.5447 - val_accuracy: 0.8016\n",
            "Epoch 148/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4445 - accuracy: 0.8371 - val_loss: 0.5633 - val_accuracy: 0.7912\n",
            "Epoch 149/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4423 - accuracy: 0.8366 - val_loss: 0.5364 - val_accuracy: 0.8091\n",
            "Epoch 150/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4317 - accuracy: 0.8391 - val_loss: 0.5551 - val_accuracy: 0.7958\n",
            "Epoch 151/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4446 - accuracy: 0.8377 - val_loss: 0.5296 - val_accuracy: 0.8097\n",
            "Epoch 152/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4322 - accuracy: 0.8445 - val_loss: 0.5426 - val_accuracy: 0.7987\n",
            "Epoch 153/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4218 - accuracy: 0.8422 - val_loss: 0.5379 - val_accuracy: 0.8080\n",
            "Epoch 154/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4349 - accuracy: 0.8394 - val_loss: 0.5320 - val_accuracy: 0.8010\n",
            "Epoch 155/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4284 - accuracy: 0.8439 - val_loss: 0.5354 - val_accuracy: 0.7964\n",
            "Epoch 156/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4243 - accuracy: 0.8451 - val_loss: 0.5531 - val_accuracy: 0.8005\n",
            "Epoch 157/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4322 - accuracy: 0.8437 - val_loss: 0.5380 - val_accuracy: 0.7964\n",
            "Epoch 158/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4244 - accuracy: 0.8417 - val_loss: 0.5530 - val_accuracy: 0.7924\n",
            "Epoch 159/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4285 - accuracy: 0.8388 - val_loss: 0.5316 - val_accuracy: 0.8120\n",
            "Epoch 160/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4200 - accuracy: 0.8439 - val_loss: 0.5387 - val_accuracy: 0.7987\n",
            "Epoch 161/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4266 - accuracy: 0.8439 - val_loss: 0.5466 - val_accuracy: 0.7947\n",
            "Epoch 162/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4158 - accuracy: 0.8462 - val_loss: 0.5309 - val_accuracy: 0.8103\n",
            "Epoch 163/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8445 - val_loss: 0.5397 - val_accuracy: 0.8108\n",
            "Epoch 164/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8536 - val_loss: 0.5362 - val_accuracy: 0.8114\n",
            "Epoch 165/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8536 - val_loss: 0.5515 - val_accuracy: 0.8010\n",
            "Epoch 166/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8502 - val_loss: 0.5576 - val_accuracy: 0.7970\n",
            "Epoch 167/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8457 - val_loss: 0.5425 - val_accuracy: 0.8045\n",
            "Epoch 168/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4026 - accuracy: 0.8482 - val_loss: 0.5442 - val_accuracy: 0.8068\n",
            "Epoch 169/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8488 - val_loss: 0.5255 - val_accuracy: 0.8057\n",
            "Epoch 170/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8530 - val_loss: 0.5266 - val_accuracy: 0.8091\n",
            "Epoch 171/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4149 - accuracy: 0.8476 - val_loss: 0.5316 - val_accuracy: 0.8028\n",
            "Epoch 172/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8519 - val_loss: 0.5272 - val_accuracy: 0.7999\n",
            "Epoch 173/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3996 - accuracy: 0.8479 - val_loss: 0.5260 - val_accuracy: 0.8126\n",
            "Epoch 174/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8445 - val_loss: 0.5310 - val_accuracy: 0.8114\n",
            "Epoch 175/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4103 - accuracy: 0.8459 - val_loss: 0.5346 - val_accuracy: 0.7999\n",
            "Epoch 176/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3980 - accuracy: 0.8528 - val_loss: 0.5202 - val_accuracy: 0.8172\n",
            "Epoch 177/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3990 - accuracy: 0.8567 - val_loss: 0.5245 - val_accuracy: 0.8068\n",
            "Epoch 178/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3990 - accuracy: 0.8536 - val_loss: 0.5182 - val_accuracy: 0.8143\n",
            "Epoch 179/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4020 - accuracy: 0.8542 - val_loss: 0.5264 - val_accuracy: 0.8091\n",
            "Epoch 180/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8528 - val_loss: 0.5305 - val_accuracy: 0.8097\n",
            "Epoch 181/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3941 - accuracy: 0.8567 - val_loss: 0.5149 - val_accuracy: 0.8201\n",
            "Epoch 182/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4030 - accuracy: 0.8448 - val_loss: 0.5155 - val_accuracy: 0.8114\n",
            "Epoch 183/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8434 - val_loss: 0.5151 - val_accuracy: 0.8143\n",
            "Epoch 184/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3950 - accuracy: 0.8593 - val_loss: 0.5388 - val_accuracy: 0.7987\n",
            "Epoch 185/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3911 - accuracy: 0.8525 - val_loss: 0.5114 - val_accuracy: 0.8091\n",
            "Epoch 186/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3916 - accuracy: 0.8567 - val_loss: 0.5237 - val_accuracy: 0.8039\n",
            "Epoch 187/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3919 - accuracy: 0.8630 - val_loss: 0.5262 - val_accuracy: 0.8045\n",
            "Epoch 188/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.8567 - val_loss: 0.5294 - val_accuracy: 0.8033\n",
            "Epoch 189/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3915 - accuracy: 0.8570 - val_loss: 0.5187 - val_accuracy: 0.8137\n",
            "Epoch 190/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4002 - accuracy: 0.8513 - val_loss: 0.5160 - val_accuracy: 0.8241\n",
            "Epoch 191/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3930 - accuracy: 0.8542 - val_loss: 0.5201 - val_accuracy: 0.8172\n",
            "Epoch 192/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8576 - val_loss: 0.5291 - val_accuracy: 0.8074\n",
            "Epoch 193/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3826 - accuracy: 0.8670 - val_loss: 0.5327 - val_accuracy: 0.8074\n",
            "Epoch 194/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3836 - accuracy: 0.8573 - val_loss: 0.5272 - val_accuracy: 0.8091\n",
            "Epoch 195/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8593 - val_loss: 0.5114 - val_accuracy: 0.8206\n",
            "Epoch 196/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3838 - accuracy: 0.8539 - val_loss: 0.5162 - val_accuracy: 0.8137\n",
            "Epoch 197/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3694 - accuracy: 0.8650 - val_loss: 0.5150 - val_accuracy: 0.8091\n",
            "Epoch 198/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3825 - accuracy: 0.8633 - val_loss: 0.5242 - val_accuracy: 0.8091\n",
            "Epoch 199/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3872 - accuracy: 0.8661 - val_loss: 0.5169 - val_accuracy: 0.8166\n",
            "Epoch 200/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3855 - accuracy: 0.8562 - val_loss: 0.5174 - val_accuracy: 0.8103\n",
            "Epoch 201/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3687 - accuracy: 0.8653 - val_loss: 0.5172 - val_accuracy: 0.8155\n",
            "Epoch 202/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3626 - accuracy: 0.8692 - val_loss: 0.5137 - val_accuracy: 0.8160\n",
            "Epoch 203/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3639 - accuracy: 0.8621 - val_loss: 0.5198 - val_accuracy: 0.8080\n",
            "Epoch 204/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3749 - accuracy: 0.8630 - val_loss: 0.5276 - val_accuracy: 0.8080\n",
            "Epoch 205/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3746 - accuracy: 0.8630 - val_loss: 0.5291 - val_accuracy: 0.8103\n",
            "Epoch 206/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8621 - val_loss: 0.5238 - val_accuracy: 0.8126\n",
            "Epoch 207/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3696 - accuracy: 0.8647 - val_loss: 0.5273 - val_accuracy: 0.8068\n",
            "Epoch 208/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3722 - accuracy: 0.8610 - val_loss: 0.5251 - val_accuracy: 0.8114\n",
            "Epoch 209/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3639 - accuracy: 0.8616 - val_loss: 0.4999 - val_accuracy: 0.8247\n",
            "Epoch 210/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3614 - accuracy: 0.8670 - val_loss: 0.5266 - val_accuracy: 0.8057\n",
            "Epoch 211/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3689 - accuracy: 0.8667 - val_loss: 0.5087 - val_accuracy: 0.8230\n",
            "Epoch 212/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3596 - accuracy: 0.8675 - val_loss: 0.5280 - val_accuracy: 0.8074\n",
            "Epoch 213/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3649 - accuracy: 0.8644 - val_loss: 0.5065 - val_accuracy: 0.8189\n",
            "Epoch 214/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3618 - accuracy: 0.8695 - val_loss: 0.5019 - val_accuracy: 0.8166\n",
            "Epoch 215/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3600 - accuracy: 0.8667 - val_loss: 0.5193 - val_accuracy: 0.8126\n",
            "Epoch 216/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3627 - accuracy: 0.8664 - val_loss: 0.5329 - val_accuracy: 0.7987\n",
            "Epoch 217/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3547 - accuracy: 0.8758 - val_loss: 0.5198 - val_accuracy: 0.8137\n",
            "Epoch 218/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3594 - accuracy: 0.8630 - val_loss: 0.5065 - val_accuracy: 0.8126\n",
            "Epoch 219/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3594 - accuracy: 0.8684 - val_loss: 0.5236 - val_accuracy: 0.8103\n",
            "Epoch 220/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3549 - accuracy: 0.8678 - val_loss: 0.5088 - val_accuracy: 0.8230\n",
            "Epoch 221/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3507 - accuracy: 0.8704 - val_loss: 0.5166 - val_accuracy: 0.8120\n",
            "Epoch 222/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3590 - accuracy: 0.8775 - val_loss: 0.4983 - val_accuracy: 0.8131\n",
            "Epoch 223/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3567 - accuracy: 0.8695 - val_loss: 0.5067 - val_accuracy: 0.8172\n",
            "Epoch 224/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3631 - accuracy: 0.8658 - val_loss: 0.5155 - val_accuracy: 0.8189\n",
            "Epoch 225/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3554 - accuracy: 0.8687 - val_loss: 0.5349 - val_accuracy: 0.8120\n",
            "Epoch 226/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3576 - accuracy: 0.8675 - val_loss: 0.5143 - val_accuracy: 0.8085\n",
            "Epoch 227/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3486 - accuracy: 0.8709 - val_loss: 0.5077 - val_accuracy: 0.8126\n",
            "Epoch 228/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3406 - accuracy: 0.8752 - val_loss: 0.5029 - val_accuracy: 0.8103\n",
            "Epoch 229/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3482 - accuracy: 0.8715 - val_loss: 0.5237 - val_accuracy: 0.8201\n",
            "Epoch 230/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3491 - accuracy: 0.8766 - val_loss: 0.5114 - val_accuracy: 0.8120\n",
            "Epoch 231/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8729 - val_loss: 0.5061 - val_accuracy: 0.8166\n",
            "Epoch 232/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8729 - val_loss: 0.5035 - val_accuracy: 0.8166\n",
            "Epoch 233/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.8701 - val_loss: 0.5237 - val_accuracy: 0.8155\n",
            "Epoch 234/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3519 - accuracy: 0.8783 - val_loss: 0.5009 - val_accuracy: 0.8183\n",
            "Epoch 235/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8789 - val_loss: 0.5277 - val_accuracy: 0.8045\n",
            "Epoch 236/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3465 - accuracy: 0.8661 - val_loss: 0.5124 - val_accuracy: 0.8131\n",
            "Epoch 237/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3364 - accuracy: 0.8761 - val_loss: 0.5097 - val_accuracy: 0.8183\n",
            "Epoch 238/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3361 - accuracy: 0.8795 - val_loss: 0.5144 - val_accuracy: 0.8143\n",
            "Epoch 239/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3440 - accuracy: 0.8749 - val_loss: 0.5086 - val_accuracy: 0.8143\n",
            "Epoch 240/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3314 - accuracy: 0.8798 - val_loss: 0.5007 - val_accuracy: 0.8137\n",
            "Epoch 241/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3443 - accuracy: 0.8749 - val_loss: 0.5017 - val_accuracy: 0.8218\n",
            "Epoch 242/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3338 - accuracy: 0.8735 - val_loss: 0.4983 - val_accuracy: 0.8149\n",
            "Epoch 243/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3390 - accuracy: 0.8732 - val_loss: 0.5019 - val_accuracy: 0.8224\n",
            "Epoch 244/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3274 - accuracy: 0.8783 - val_loss: 0.5108 - val_accuracy: 0.8120\n",
            "Epoch 245/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3291 - accuracy: 0.8818 - val_loss: 0.5033 - val_accuracy: 0.8166\n",
            "Epoch 246/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3401 - accuracy: 0.8769 - val_loss: 0.5080 - val_accuracy: 0.8206\n",
            "Epoch 247/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3362 - accuracy: 0.8744 - val_loss: 0.4989 - val_accuracy: 0.8276\n",
            "Epoch 248/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3305 - accuracy: 0.8789 - val_loss: 0.4884 - val_accuracy: 0.8293\n",
            "Epoch 249/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3253 - accuracy: 0.8761 - val_loss: 0.5007 - val_accuracy: 0.8264\n",
            "Epoch 250/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3292 - accuracy: 0.8798 - val_loss: 0.5049 - val_accuracy: 0.8241\n",
            "Epoch 251/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.8800 - val_loss: 0.5047 - val_accuracy: 0.8235\n",
            "Epoch 252/1000\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.3295 - accuracy: 0.8818 - val_loss: 0.4962 - val_accuracy: 0.8230\n",
            "Epoch 253/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3212 - accuracy: 0.8891 - val_loss: 0.5046 - val_accuracy: 0.8241\n",
            "Epoch 254/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3201 - accuracy: 0.8800 - val_loss: 0.5052 - val_accuracy: 0.8178\n",
            "Epoch 255/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3258 - accuracy: 0.8766 - val_loss: 0.5252 - val_accuracy: 0.8114\n",
            "Epoch 256/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3249 - accuracy: 0.8837 - val_loss: 0.4879 - val_accuracy: 0.8253\n",
            "Epoch 257/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3299 - accuracy: 0.8783 - val_loss: 0.4955 - val_accuracy: 0.8230\n",
            "Epoch 258/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3155 - accuracy: 0.8849 - val_loss: 0.5043 - val_accuracy: 0.8149\n",
            "Epoch 259/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3188 - accuracy: 0.8860 - val_loss: 0.5010 - val_accuracy: 0.8258\n",
            "Epoch 260/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3250 - accuracy: 0.8744 - val_loss: 0.4927 - val_accuracy: 0.8310\n",
            "Epoch 261/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3217 - accuracy: 0.8872 - val_loss: 0.5044 - val_accuracy: 0.8166\n",
            "Epoch 262/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3207 - accuracy: 0.8854 - val_loss: 0.4949 - val_accuracy: 0.8212\n",
            "Epoch 263/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3161 - accuracy: 0.8826 - val_loss: 0.4984 - val_accuracy: 0.8247\n",
            "Epoch 264/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3250 - accuracy: 0.8894 - val_loss: 0.5000 - val_accuracy: 0.8155\n",
            "Epoch 265/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3172 - accuracy: 0.8880 - val_loss: 0.5004 - val_accuracy: 0.8212\n",
            "Epoch 266/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3097 - accuracy: 0.8849 - val_loss: 0.5052 - val_accuracy: 0.8230\n",
            "Epoch 267/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3139 - accuracy: 0.8809 - val_loss: 0.5042 - val_accuracy: 0.8212\n",
            "Epoch 268/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3243 - accuracy: 0.8857 - val_loss: 0.4899 - val_accuracy: 0.8206\n",
            "Epoch 269/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3154 - accuracy: 0.8908 - val_loss: 0.5064 - val_accuracy: 0.8224\n",
            "Epoch 270/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3160 - accuracy: 0.8852 - val_loss: 0.5046 - val_accuracy: 0.8195\n",
            "Epoch 271/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3127 - accuracy: 0.8823 - val_loss: 0.5056 - val_accuracy: 0.8189\n",
            "Epoch 272/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3187 - accuracy: 0.8894 - val_loss: 0.5012 - val_accuracy: 0.8189\n",
            "Epoch 273/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3067 - accuracy: 0.8854 - val_loss: 0.5083 - val_accuracy: 0.8166\n",
            "Epoch 274/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3004 - accuracy: 0.8931 - val_loss: 0.4998 - val_accuracy: 0.8224\n",
            "Epoch 275/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3016 - accuracy: 0.8928 - val_loss: 0.5049 - val_accuracy: 0.8281\n",
            "Epoch 276/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.3168 - accuracy: 0.8889 - val_loss: 0.5079 - val_accuracy: 0.8160\n",
            "Epoch 277/1000\n",
            "220/220 [==============================] - 1s 7ms/step - loss: 0.3009 - accuracy: 0.8877 - val_loss: 0.5033 - val_accuracy: 0.8206\n",
            "Epoch 278/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.3048 - accuracy: 0.8860 - val_loss: 0.4956 - val_accuracy: 0.8201\n",
            "Epoch 279/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3012 - accuracy: 0.8940 - val_loss: 0.5049 - val_accuracy: 0.8178\n",
            "Epoch 280/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3106 - accuracy: 0.8911 - val_loss: 0.4998 - val_accuracy: 0.8126\n",
            "Epoch 281/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3004 - accuracy: 0.8931 - val_loss: 0.4984 - val_accuracy: 0.8172\n",
            "Epoch 282/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2977 - accuracy: 0.8940 - val_loss: 0.4868 - val_accuracy: 0.8328\n",
            "Epoch 283/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2969 - accuracy: 0.8928 - val_loss: 0.5167 - val_accuracy: 0.8097\n",
            "Epoch 284/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3104 - accuracy: 0.8920 - val_loss: 0.5083 - val_accuracy: 0.8241\n",
            "Epoch 285/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.8931 - val_loss: 0.4987 - val_accuracy: 0.8235\n",
            "Epoch 286/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.8897 - val_loss: 0.5078 - val_accuracy: 0.8241\n",
            "Epoch 287/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3133 - accuracy: 0.8863 - val_loss: 0.5021 - val_accuracy: 0.8183\n",
            "Epoch 288/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2934 - accuracy: 0.8923 - val_loss: 0.4934 - val_accuracy: 0.8276\n",
            "Epoch 289/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2913 - accuracy: 0.8960 - val_loss: 0.4917 - val_accuracy: 0.8281\n",
            "Epoch 290/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3040 - accuracy: 0.8923 - val_loss: 0.4869 - val_accuracy: 0.8310\n",
            "Epoch 291/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2915 - accuracy: 0.8940 - val_loss: 0.5029 - val_accuracy: 0.8201\n",
            "Epoch 292/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2943 - accuracy: 0.8940 - val_loss: 0.4946 - val_accuracy: 0.8276\n",
            "Epoch 293/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.8968 - val_loss: 0.4931 - val_accuracy: 0.8270\n",
            "Epoch 294/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2981 - accuracy: 0.8883 - val_loss: 0.5015 - val_accuracy: 0.8201\n",
            "Epoch 295/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2928 - accuracy: 0.8943 - val_loss: 0.4903 - val_accuracy: 0.8356\n",
            "Epoch 296/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2781 - accuracy: 0.8951 - val_loss: 0.4954 - val_accuracy: 0.8304\n",
            "Epoch 297/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3006 - accuracy: 0.8877 - val_loss: 0.5051 - val_accuracy: 0.8201\n",
            "Epoch 298/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2876 - accuracy: 0.8954 - val_loss: 0.4950 - val_accuracy: 0.8230\n",
            "Epoch 299/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2835 - accuracy: 0.8982 - val_loss: 0.4942 - val_accuracy: 0.8287\n",
            "Epoch 300/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2961 - accuracy: 0.8926 - val_loss: 0.4888 - val_accuracy: 0.8333\n",
            "Epoch 301/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2861 - accuracy: 0.8971 - val_loss: 0.5156 - val_accuracy: 0.8235\n",
            "Epoch 302/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2882 - accuracy: 0.8948 - val_loss: 0.5237 - val_accuracy: 0.8206\n",
            "Epoch 303/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2877 - accuracy: 0.8962 - val_loss: 0.4996 - val_accuracy: 0.8189\n",
            "Epoch 304/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2801 - accuracy: 0.8928 - val_loss: 0.4956 - val_accuracy: 0.8212\n",
            "Epoch 305/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2868 - accuracy: 0.8926 - val_loss: 0.5151 - val_accuracy: 0.8241\n",
            "Epoch 306/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2875 - accuracy: 0.8965 - val_loss: 0.5031 - val_accuracy: 0.8241\n",
            "Epoch 307/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2782 - accuracy: 0.8965 - val_loss: 0.4963 - val_accuracy: 0.8218\n",
            "Epoch 308/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2819 - accuracy: 0.8900 - val_loss: 0.5037 - val_accuracy: 0.8155\n",
            "Epoch 309/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2835 - accuracy: 0.8945 - val_loss: 0.4929 - val_accuracy: 0.8276\n",
            "Epoch 310/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2777 - accuracy: 0.9016 - val_loss: 0.4974 - val_accuracy: 0.8253\n",
            "Epoch 311/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2838 - accuracy: 0.8957 - val_loss: 0.5019 - val_accuracy: 0.8247\n",
            "Epoch 312/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2883 - accuracy: 0.8934 - val_loss: 0.4866 - val_accuracy: 0.8258\n",
            "Epoch 313/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2835 - accuracy: 0.8945 - val_loss: 0.4949 - val_accuracy: 0.8276\n",
            "Epoch 314/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2829 - accuracy: 0.8974 - val_loss: 0.4958 - val_accuracy: 0.8270\n",
            "Epoch 315/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2788 - accuracy: 0.8960 - val_loss: 0.5086 - val_accuracy: 0.8281\n",
            "Epoch 316/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2681 - accuracy: 0.9005 - val_loss: 0.5022 - val_accuracy: 0.8304\n",
            "Epoch 317/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2763 - accuracy: 0.9005 - val_loss: 0.5035 - val_accuracy: 0.8195\n",
            "Epoch 318/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2733 - accuracy: 0.8997 - val_loss: 0.5321 - val_accuracy: 0.8230\n",
            "Epoch 319/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2745 - accuracy: 0.9008 - val_loss: 0.5049 - val_accuracy: 0.8160\n",
            "Epoch 320/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2690 - accuracy: 0.9039 - val_loss: 0.5083 - val_accuracy: 0.8270\n",
            "Epoch 321/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2767 - accuracy: 0.9008 - val_loss: 0.5099 - val_accuracy: 0.8264\n",
            "Epoch 322/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2779 - accuracy: 0.8982 - val_loss: 0.4874 - val_accuracy: 0.8253\n",
            "Epoch 323/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2757 - accuracy: 0.9022 - val_loss: 0.5189 - val_accuracy: 0.8149\n",
            "Epoch 324/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2666 - accuracy: 0.9011 - val_loss: 0.4882 - val_accuracy: 0.8328\n",
            "Epoch 325/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2755 - accuracy: 0.8971 - val_loss: 0.4897 - val_accuracy: 0.8270\n",
            "Epoch 326/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2681 - accuracy: 0.9025 - val_loss: 0.4798 - val_accuracy: 0.8379\n",
            "Epoch 327/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2659 - accuracy: 0.9110 - val_loss: 0.4962 - val_accuracy: 0.8281\n",
            "Epoch 328/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2667 - accuracy: 0.9019 - val_loss: 0.4842 - val_accuracy: 0.8316\n",
            "Epoch 329/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2656 - accuracy: 0.9053 - val_loss: 0.4940 - val_accuracy: 0.8374\n",
            "Epoch 330/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2714 - accuracy: 0.9016 - val_loss: 0.4857 - val_accuracy: 0.8362\n",
            "Epoch 331/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2638 - accuracy: 0.9016 - val_loss: 0.4969 - val_accuracy: 0.8328\n",
            "Epoch 332/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2647 - accuracy: 0.9025 - val_loss: 0.4971 - val_accuracy: 0.8224\n",
            "Epoch 333/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2630 - accuracy: 0.9099 - val_loss: 0.4946 - val_accuracy: 0.8281\n",
            "Epoch 334/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2672 - accuracy: 0.9025 - val_loss: 0.5095 - val_accuracy: 0.8224\n",
            "Epoch 335/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2605 - accuracy: 0.9056 - val_loss: 0.4905 - val_accuracy: 0.8247\n",
            "Epoch 336/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2657 - accuracy: 0.9034 - val_loss: 0.5062 - val_accuracy: 0.8230\n",
            "Epoch 337/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2665 - accuracy: 0.9039 - val_loss: 0.5038 - val_accuracy: 0.8328\n",
            "Epoch 338/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2643 - accuracy: 0.9016 - val_loss: 0.4828 - val_accuracy: 0.8362\n",
            "Epoch 339/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2558 - accuracy: 0.9070 - val_loss: 0.5098 - val_accuracy: 0.8293\n",
            "Epoch 340/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2527 - accuracy: 0.9122 - val_loss: 0.4986 - val_accuracy: 0.8218\n",
            "Epoch 341/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2503 - accuracy: 0.9085 - val_loss: 0.5020 - val_accuracy: 0.8212\n",
            "Epoch 342/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2464 - accuracy: 0.9133 - val_loss: 0.5061 - val_accuracy: 0.8270\n",
            "Epoch 343/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2598 - accuracy: 0.9079 - val_loss: 0.5112 - val_accuracy: 0.8281\n",
            "Epoch 344/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2545 - accuracy: 0.9122 - val_loss: 0.5200 - val_accuracy: 0.8264\n",
            "Epoch 345/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2557 - accuracy: 0.9036 - val_loss: 0.4897 - val_accuracy: 0.8310\n",
            "Epoch 346/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2616 - accuracy: 0.9068 - val_loss: 0.4963 - val_accuracy: 0.8270\n",
            "Epoch 347/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2503 - accuracy: 0.9107 - val_loss: 0.5021 - val_accuracy: 0.8316\n",
            "Epoch 348/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2562 - accuracy: 0.9068 - val_loss: 0.5366 - val_accuracy: 0.8155\n",
            "Epoch 349/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2492 - accuracy: 0.9073 - val_loss: 0.4993 - val_accuracy: 0.8264\n",
            "Epoch 350/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2536 - accuracy: 0.9056 - val_loss: 0.4849 - val_accuracy: 0.8356\n",
            "Epoch 351/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2508 - accuracy: 0.9085 - val_loss: 0.5136 - val_accuracy: 0.8258\n",
            "Epoch 352/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2629 - accuracy: 0.9034 - val_loss: 0.5124 - val_accuracy: 0.8224\n",
            "Epoch 353/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2509 - accuracy: 0.9110 - val_loss: 0.5048 - val_accuracy: 0.8206\n",
            "Epoch 354/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2553 - accuracy: 0.9068 - val_loss: 0.5036 - val_accuracy: 0.8281\n",
            "Epoch 355/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2518 - accuracy: 0.9076 - val_loss: 0.4945 - val_accuracy: 0.8374\n",
            "Epoch 356/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2628 - accuracy: 0.9065 - val_loss: 0.4885 - val_accuracy: 0.8356\n",
            "Epoch 357/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2537 - accuracy: 0.9110 - val_loss: 0.5044 - val_accuracy: 0.8304\n",
            "Epoch 358/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2469 - accuracy: 0.9076 - val_loss: 0.5016 - val_accuracy: 0.8310\n",
            "Epoch 359/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2448 - accuracy: 0.9164 - val_loss: 0.5055 - val_accuracy: 0.8264\n",
            "Epoch 360/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2493 - accuracy: 0.9070 - val_loss: 0.4962 - val_accuracy: 0.8362\n",
            "Epoch 361/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2546 - accuracy: 0.9096 - val_loss: 0.4901 - val_accuracy: 0.8316\n",
            "Epoch 362/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2501 - accuracy: 0.9090 - val_loss: 0.5435 - val_accuracy: 0.8080\n",
            "Epoch 363/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2425 - accuracy: 0.9122 - val_loss: 0.4970 - val_accuracy: 0.8281\n",
            "Epoch 364/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2420 - accuracy: 0.9133 - val_loss: 0.4980 - val_accuracy: 0.8345\n",
            "Epoch 365/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2456 - accuracy: 0.9122 - val_loss: 0.4959 - val_accuracy: 0.8310\n",
            "Epoch 366/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2417 - accuracy: 0.9110 - val_loss: 0.5024 - val_accuracy: 0.8299\n",
            "Epoch 367/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2459 - accuracy: 0.9102 - val_loss: 0.5421 - val_accuracy: 0.8120\n",
            "Epoch 368/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2443 - accuracy: 0.9119 - val_loss: 0.4978 - val_accuracy: 0.8379\n",
            "Epoch 369/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2424 - accuracy: 0.9156 - val_loss: 0.4947 - val_accuracy: 0.8322\n",
            "Epoch 370/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2405 - accuracy: 0.9167 - val_loss: 0.4939 - val_accuracy: 0.8408\n",
            "Epoch 371/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2465 - accuracy: 0.9127 - val_loss: 0.4890 - val_accuracy: 0.8391\n",
            "Epoch 372/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2334 - accuracy: 0.9181 - val_loss: 0.5084 - val_accuracy: 0.8310\n",
            "Epoch 373/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2351 - accuracy: 0.9164 - val_loss: 0.4943 - val_accuracy: 0.8258\n",
            "Epoch 374/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2438 - accuracy: 0.9133 - val_loss: 0.4875 - val_accuracy: 0.8328\n",
            "Epoch 375/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2343 - accuracy: 0.9153 - val_loss: 0.4927 - val_accuracy: 0.8264\n",
            "Epoch 376/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2305 - accuracy: 0.9181 - val_loss: 0.4861 - val_accuracy: 0.8299\n",
            "Epoch 377/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2282 - accuracy: 0.9193 - val_loss: 0.4966 - val_accuracy: 0.8293\n",
            "Epoch 378/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2405 - accuracy: 0.9110 - val_loss: 0.5119 - val_accuracy: 0.8293\n",
            "Epoch 379/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2333 - accuracy: 0.9144 - val_loss: 0.5186 - val_accuracy: 0.8258\n",
            "Epoch 380/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2395 - accuracy: 0.9125 - val_loss: 0.4966 - val_accuracy: 0.8316\n",
            "Epoch 381/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2404 - accuracy: 0.9125 - val_loss: 0.5054 - val_accuracy: 0.8281\n",
            "Epoch 382/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2320 - accuracy: 0.9204 - val_loss: 0.5077 - val_accuracy: 0.8420\n",
            "Epoch 383/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2363 - accuracy: 0.9201 - val_loss: 0.4967 - val_accuracy: 0.8356\n",
            "Epoch 384/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2353 - accuracy: 0.9176 - val_loss: 0.5086 - val_accuracy: 0.8316\n",
            "Epoch 385/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2272 - accuracy: 0.9196 - val_loss: 0.5001 - val_accuracy: 0.8322\n",
            "Epoch 386/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2379 - accuracy: 0.9142 - val_loss: 0.4994 - val_accuracy: 0.8276\n",
            "Epoch 387/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2261 - accuracy: 0.9147 - val_loss: 0.5037 - val_accuracy: 0.8379\n",
            "Epoch 388/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2293 - accuracy: 0.9139 - val_loss: 0.5002 - val_accuracy: 0.8339\n",
            "Epoch 389/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2281 - accuracy: 0.9204 - val_loss: 0.5023 - val_accuracy: 0.8356\n",
            "Epoch 390/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2360 - accuracy: 0.9150 - val_loss: 0.4811 - val_accuracy: 0.8397\n",
            "Epoch 391/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2284 - accuracy: 0.9193 - val_loss: 0.4996 - val_accuracy: 0.8264\n",
            "Epoch 392/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2300 - accuracy: 0.9161 - val_loss: 0.4954 - val_accuracy: 0.8316\n",
            "Epoch 393/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2341 - accuracy: 0.9164 - val_loss: 0.5050 - val_accuracy: 0.8368\n",
            "Epoch 394/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2238 - accuracy: 0.9187 - val_loss: 0.5026 - val_accuracy: 0.8322\n",
            "Epoch 395/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2282 - accuracy: 0.9193 - val_loss: 0.5033 - val_accuracy: 0.8258\n",
            "Epoch 396/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2198 - accuracy: 0.9238 - val_loss: 0.5068 - val_accuracy: 0.8287\n",
            "Epoch 397/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2304 - accuracy: 0.9147 - val_loss: 0.4864 - val_accuracy: 0.8408\n",
            "Epoch 398/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2281 - accuracy: 0.9187 - val_loss: 0.4979 - val_accuracy: 0.8368\n",
            "Epoch 399/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2240 - accuracy: 0.9215 - val_loss: 0.5049 - val_accuracy: 0.8316\n",
            "Epoch 400/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2276 - accuracy: 0.9176 - val_loss: 0.4836 - val_accuracy: 0.8403\n",
            "Epoch 401/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2257 - accuracy: 0.9204 - val_loss: 0.4959 - val_accuracy: 0.8316\n",
            "Epoch 402/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2322 - accuracy: 0.9184 - val_loss: 0.5080 - val_accuracy: 0.8339\n",
            "Epoch 403/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2282 - accuracy: 0.9244 - val_loss: 0.5071 - val_accuracy: 0.8287\n",
            "Epoch 404/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2180 - accuracy: 0.9238 - val_loss: 0.5026 - val_accuracy: 0.8322\n",
            "Epoch 405/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2243 - accuracy: 0.9167 - val_loss: 0.5110 - val_accuracy: 0.8391\n",
            "Epoch 406/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2307 - accuracy: 0.9150 - val_loss: 0.5037 - val_accuracy: 0.8345\n",
            "Epoch 407/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2109 - accuracy: 0.9275 - val_loss: 0.5154 - val_accuracy: 0.8322\n",
            "Epoch 408/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2239 - accuracy: 0.9241 - val_loss: 0.5078 - val_accuracy: 0.8333\n",
            "Epoch 409/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2235 - accuracy: 0.9198 - val_loss: 0.5192 - val_accuracy: 0.8368\n",
            "Epoch 410/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2116 - accuracy: 0.9264 - val_loss: 0.5073 - val_accuracy: 0.8374\n",
            "Epoch 411/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2162 - accuracy: 0.9224 - val_loss: 0.4993 - val_accuracy: 0.8379\n",
            "Epoch 412/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2246 - accuracy: 0.9167 - val_loss: 0.4995 - val_accuracy: 0.8368\n",
            "Epoch 413/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2147 - accuracy: 0.9233 - val_loss: 0.4923 - val_accuracy: 0.8420\n",
            "Epoch 414/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2246 - accuracy: 0.9193 - val_loss: 0.4921 - val_accuracy: 0.8403\n",
            "Epoch 415/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2170 - accuracy: 0.9204 - val_loss: 0.4940 - val_accuracy: 0.8351\n",
            "Epoch 416/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9298 - val_loss: 0.5002 - val_accuracy: 0.8408\n",
            "Epoch 417/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2192 - accuracy: 0.9190 - val_loss: 0.5028 - val_accuracy: 0.8310\n",
            "Epoch 418/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9227 - val_loss: 0.4880 - val_accuracy: 0.8431\n",
            "Epoch 419/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2056 - accuracy: 0.9298 - val_loss: 0.5179 - val_accuracy: 0.8287\n",
            "Epoch 420/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2057 - accuracy: 0.9227 - val_loss: 0.5060 - val_accuracy: 0.8385\n",
            "Epoch 421/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2152 - accuracy: 0.9227 - val_loss: 0.5289 - val_accuracy: 0.8316\n",
            "Epoch 422/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2042 - accuracy: 0.9269 - val_loss: 0.5014 - val_accuracy: 0.8362\n",
            "Epoch 423/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2131 - accuracy: 0.9281 - val_loss: 0.5164 - val_accuracy: 0.8293\n",
            "Epoch 424/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9252 - val_loss: 0.5052 - val_accuracy: 0.8333\n",
            "Epoch 425/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2122 - accuracy: 0.9264 - val_loss: 0.5088 - val_accuracy: 0.8264\n",
            "Epoch 426/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2118 - accuracy: 0.9241 - val_loss: 0.5158 - val_accuracy: 0.8322\n",
            "Epoch 427/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2197 - accuracy: 0.9196 - val_loss: 0.4997 - val_accuracy: 0.8345\n",
            "Epoch 428/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2156 - accuracy: 0.9215 - val_loss: 0.5104 - val_accuracy: 0.8333\n",
            "Epoch 429/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2035 - accuracy: 0.9272 - val_loss: 0.5061 - val_accuracy: 0.8322\n",
            "Epoch 430/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9247 - val_loss: 0.4994 - val_accuracy: 0.8374\n",
            "Epoch 431/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2040 - accuracy: 0.9247 - val_loss: 0.5009 - val_accuracy: 0.8368\n",
            "Epoch 432/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9230 - val_loss: 0.5097 - val_accuracy: 0.8345\n",
            "Epoch 433/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2073 - accuracy: 0.9272 - val_loss: 0.5161 - val_accuracy: 0.8299\n",
            "Epoch 434/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2083 - accuracy: 0.9264 - val_loss: 0.5206 - val_accuracy: 0.8270\n",
            "Epoch 435/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2153 - accuracy: 0.9258 - val_loss: 0.4918 - val_accuracy: 0.8449\n",
            "Epoch 436/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9309 - val_loss: 0.5097 - val_accuracy: 0.8235\n",
            "Epoch 437/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9284 - val_loss: 0.4904 - val_accuracy: 0.8328\n",
            "Epoch 438/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2051 - accuracy: 0.9235 - val_loss: 0.5073 - val_accuracy: 0.8270\n",
            "Epoch 439/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2021 - accuracy: 0.9261 - val_loss: 0.5119 - val_accuracy: 0.8397\n",
            "Epoch 440/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2137 - accuracy: 0.9255 - val_loss: 0.5030 - val_accuracy: 0.8385\n",
            "Epoch 441/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1998 - accuracy: 0.9264 - val_loss: 0.5128 - val_accuracy: 0.8345\n",
            "Epoch 442/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9287 - val_loss: 0.5078 - val_accuracy: 0.8328\n",
            "Epoch 443/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2076 - accuracy: 0.9264 - val_loss: 0.5150 - val_accuracy: 0.8281\n",
            "Epoch 444/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2108 - accuracy: 0.9269 - val_loss: 0.5075 - val_accuracy: 0.8443\n",
            "Epoch 445/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1953 - accuracy: 0.9255 - val_loss: 0.4851 - val_accuracy: 0.8403\n",
            "Epoch 446/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2024 - accuracy: 0.9301 - val_loss: 0.5022 - val_accuracy: 0.8374\n",
            "Epoch 447/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1932 - accuracy: 0.9295 - val_loss: 0.5095 - val_accuracy: 0.8333\n",
            "Epoch 448/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1973 - accuracy: 0.9338 - val_loss: 0.5169 - val_accuracy: 0.8281\n",
            "Epoch 449/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1930 - accuracy: 0.9304 - val_loss: 0.4777 - val_accuracy: 0.8397\n",
            "Epoch 450/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1996 - accuracy: 0.9329 - val_loss: 0.5113 - val_accuracy: 0.8310\n",
            "Epoch 451/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1966 - accuracy: 0.9358 - val_loss: 0.5038 - val_accuracy: 0.8333\n",
            "Epoch 452/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9289 - val_loss: 0.5137 - val_accuracy: 0.8316\n",
            "Epoch 453/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1982 - accuracy: 0.9264 - val_loss: 0.5153 - val_accuracy: 0.8333\n",
            "Epoch 454/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.2000 - accuracy: 0.9323 - val_loss: 0.5238 - val_accuracy: 0.8287\n",
            "Epoch 455/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1913 - accuracy: 0.9321 - val_loss: 0.5141 - val_accuracy: 0.8322\n",
            "Epoch 456/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1909 - accuracy: 0.9326 - val_loss: 0.5073 - val_accuracy: 0.8362\n",
            "Epoch 457/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1885 - accuracy: 0.9292 - val_loss: 0.5074 - val_accuracy: 0.8368\n",
            "Epoch 458/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1911 - accuracy: 0.9332 - val_loss: 0.5144 - val_accuracy: 0.8356\n",
            "Epoch 459/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1803 - accuracy: 0.9375 - val_loss: 0.4979 - val_accuracy: 0.8391\n",
            "Epoch 460/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1931 - accuracy: 0.9321 - val_loss: 0.4938 - val_accuracy: 0.8449\n",
            "Epoch 461/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1951 - accuracy: 0.9272 - val_loss: 0.4891 - val_accuracy: 0.8397\n",
            "Epoch 462/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1854 - accuracy: 0.9360 - val_loss: 0.4897 - val_accuracy: 0.8385\n",
            "Epoch 463/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1939 - accuracy: 0.9304 - val_loss: 0.5104 - val_accuracy: 0.8356\n",
            "Epoch 464/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1928 - accuracy: 0.9312 - val_loss: 0.5065 - val_accuracy: 0.8287\n",
            "Epoch 465/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1854 - accuracy: 0.9358 - val_loss: 0.5024 - val_accuracy: 0.8345\n",
            "Epoch 466/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1908 - accuracy: 0.9304 - val_loss: 0.5076 - val_accuracy: 0.8293\n",
            "Epoch 467/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1991 - accuracy: 0.9241 - val_loss: 0.5267 - val_accuracy: 0.8241\n",
            "Epoch 468/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1799 - accuracy: 0.9372 - val_loss: 0.5075 - val_accuracy: 0.8391\n",
            "Epoch 469/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1811 - accuracy: 0.9309 - val_loss: 0.5143 - val_accuracy: 0.8299\n",
            "Epoch 470/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1880 - accuracy: 0.9335 - val_loss: 0.5207 - val_accuracy: 0.8316\n",
            "Epoch 471/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1814 - accuracy: 0.9375 - val_loss: 0.5065 - val_accuracy: 0.8345\n",
            "Epoch 472/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1795 - accuracy: 0.9380 - val_loss: 0.5229 - val_accuracy: 0.8403\n",
            "Epoch 473/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1848 - accuracy: 0.9395 - val_loss: 0.5038 - val_accuracy: 0.8374\n",
            "Epoch 474/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1913 - accuracy: 0.9343 - val_loss: 0.5138 - val_accuracy: 0.8379\n",
            "Epoch 475/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1900 - accuracy: 0.9264 - val_loss: 0.5006 - val_accuracy: 0.8391\n",
            "Epoch 476/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1850 - accuracy: 0.9377 - val_loss: 0.5090 - val_accuracy: 0.8345\n",
            "Epoch 477/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1914 - accuracy: 0.9306 - val_loss: 0.5102 - val_accuracy: 0.8374\n",
            "Epoch 478/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1842 - accuracy: 0.9355 - val_loss: 0.5018 - val_accuracy: 0.8345\n",
            "Epoch 479/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1824 - accuracy: 0.9343 - val_loss: 0.5136 - val_accuracy: 0.8333\n",
            "Epoch 480/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1873 - accuracy: 0.9278 - val_loss: 0.5210 - val_accuracy: 0.8339\n",
            "Epoch 481/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1876 - accuracy: 0.9332 - val_loss: 0.5280 - val_accuracy: 0.8322\n",
            "Epoch 482/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1835 - accuracy: 0.9338 - val_loss: 0.4992 - val_accuracy: 0.8379\n",
            "Epoch 483/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1872 - accuracy: 0.9323 - val_loss: 0.5197 - val_accuracy: 0.8333\n",
            "Epoch 484/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1787 - accuracy: 0.9395 - val_loss: 0.5364 - val_accuracy: 0.8276\n",
            "Epoch 485/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1812 - accuracy: 0.9369 - val_loss: 0.5540 - val_accuracy: 0.8224\n",
            "Epoch 486/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1854 - accuracy: 0.9341 - val_loss: 0.5037 - val_accuracy: 0.8362\n",
            "Epoch 487/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1741 - accuracy: 0.9397 - val_loss: 0.5315 - val_accuracy: 0.8299\n",
            "Epoch 488/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1807 - accuracy: 0.9369 - val_loss: 0.5191 - val_accuracy: 0.8328\n",
            "Epoch 489/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1793 - accuracy: 0.9318 - val_loss: 0.5223 - val_accuracy: 0.8333\n",
            "Epoch 490/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1779 - accuracy: 0.9352 - val_loss: 0.5217 - val_accuracy: 0.8328\n",
            "Epoch 491/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1831 - accuracy: 0.9377 - val_loss: 0.5157 - val_accuracy: 0.8328\n",
            "Epoch 492/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1764 - accuracy: 0.9397 - val_loss: 0.5210 - val_accuracy: 0.8362\n",
            "Epoch 493/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1740 - accuracy: 0.9386 - val_loss: 0.5317 - val_accuracy: 0.8362\n",
            "Epoch 494/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9363 - val_loss: 0.5555 - val_accuracy: 0.8328\n",
            "Epoch 495/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1698 - accuracy: 0.9426 - val_loss: 0.5266 - val_accuracy: 0.8322\n",
            "Epoch 496/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1816 - accuracy: 0.9332 - val_loss: 0.5548 - val_accuracy: 0.8356\n",
            "Epoch 497/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1749 - accuracy: 0.9341 - val_loss: 0.5139 - val_accuracy: 0.8351\n",
            "Epoch 498/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1718 - accuracy: 0.9383 - val_loss: 0.5121 - val_accuracy: 0.8403\n",
            "Epoch 499/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1793 - accuracy: 0.9358 - val_loss: 0.5049 - val_accuracy: 0.8414\n",
            "Epoch 500/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1689 - accuracy: 0.9395 - val_loss: 0.5449 - val_accuracy: 0.8247\n",
            "Epoch 501/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1687 - accuracy: 0.9380 - val_loss: 0.5334 - val_accuracy: 0.8293\n",
            "Epoch 502/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.9395 - val_loss: 0.5238 - val_accuracy: 0.8385\n",
            "Epoch 503/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1751 - accuracy: 0.9397 - val_loss: 0.5045 - val_accuracy: 0.8379\n",
            "Epoch 504/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1760 - accuracy: 0.9346 - val_loss: 0.5114 - val_accuracy: 0.8351\n",
            "Epoch 505/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1709 - accuracy: 0.9372 - val_loss: 0.5282 - val_accuracy: 0.8230\n",
            "Epoch 506/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1770 - accuracy: 0.9395 - val_loss: 0.5250 - val_accuracy: 0.8351\n",
            "Epoch 507/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1771 - accuracy: 0.9355 - val_loss: 0.5248 - val_accuracy: 0.8385\n",
            "Epoch 508/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1759 - accuracy: 0.9375 - val_loss: 0.5238 - val_accuracy: 0.8351\n",
            "Epoch 509/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1794 - accuracy: 0.9346 - val_loss: 0.5437 - val_accuracy: 0.8247\n",
            "Epoch 510/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1625 - accuracy: 0.9417 - val_loss: 0.5406 - val_accuracy: 0.8328\n",
            "Epoch 511/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1721 - accuracy: 0.9383 - val_loss: 0.5460 - val_accuracy: 0.8351\n",
            "Epoch 512/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1657 - accuracy: 0.9457 - val_loss: 0.5253 - val_accuracy: 0.8345\n",
            "Epoch 513/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1756 - accuracy: 0.9375 - val_loss: 0.5207 - val_accuracy: 0.8345\n",
            "Epoch 514/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1683 - accuracy: 0.9386 - val_loss: 0.5412 - val_accuracy: 0.8328\n",
            "Epoch 515/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1687 - accuracy: 0.9431 - val_loss: 0.5155 - val_accuracy: 0.8397\n",
            "Epoch 516/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1706 - accuracy: 0.9403 - val_loss: 0.5326 - val_accuracy: 0.8276\n",
            "Epoch 517/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1666 - accuracy: 0.9423 - val_loss: 0.5120 - val_accuracy: 0.8420\n",
            "Epoch 518/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1716 - accuracy: 0.9395 - val_loss: 0.5289 - val_accuracy: 0.8304\n",
            "Epoch 519/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1667 - accuracy: 0.9437 - val_loss: 0.5144 - val_accuracy: 0.8356\n",
            "Epoch 520/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1710 - accuracy: 0.9389 - val_loss: 0.5237 - val_accuracy: 0.8443\n",
            "Epoch 521/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1683 - accuracy: 0.9366 - val_loss: 0.5291 - val_accuracy: 0.8328\n",
            "Epoch 522/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1599 - accuracy: 0.9426 - val_loss: 0.5272 - val_accuracy: 0.8420\n",
            "Epoch 523/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1639 - accuracy: 0.9412 - val_loss: 0.5387 - val_accuracy: 0.8270\n",
            "Epoch 524/1000\n",
            "220/220 [==============================] - 1s 7ms/step - loss: 0.1622 - accuracy: 0.9426 - val_loss: 0.5069 - val_accuracy: 0.8408\n",
            "Epoch 525/1000\n",
            "220/220 [==============================] - 2s 7ms/step - loss: 0.1695 - accuracy: 0.9446 - val_loss: 0.5147 - val_accuracy: 0.8449\n",
            "Epoch 526/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1655 - accuracy: 0.9403 - val_loss: 0.5530 - val_accuracy: 0.8339\n",
            "Epoch 527/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9431 - val_loss: 0.5297 - val_accuracy: 0.8356\n",
            "Epoch 528/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1676 - accuracy: 0.9440 - val_loss: 0.5181 - val_accuracy: 0.8420\n",
            "Epoch 529/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1573 - accuracy: 0.9457 - val_loss: 0.5453 - val_accuracy: 0.8322\n",
            "Epoch 530/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1643 - accuracy: 0.9400 - val_loss: 0.5407 - val_accuracy: 0.8414\n",
            "Epoch 531/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1740 - accuracy: 0.9363 - val_loss: 0.5224 - val_accuracy: 0.8391\n",
            "Epoch 532/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1583 - accuracy: 0.9449 - val_loss: 0.5369 - val_accuracy: 0.8264\n",
            "Epoch 533/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1527 - accuracy: 0.9446 - val_loss: 0.5339 - val_accuracy: 0.8345\n",
            "Epoch 534/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1565 - accuracy: 0.9434 - val_loss: 0.5416 - val_accuracy: 0.8339\n",
            "Epoch 535/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1575 - accuracy: 0.9397 - val_loss: 0.5391 - val_accuracy: 0.8333\n",
            "Epoch 536/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1645 - accuracy: 0.9437 - val_loss: 0.5331 - val_accuracy: 0.8322\n",
            "Epoch 537/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1616 - accuracy: 0.9443 - val_loss: 0.5396 - val_accuracy: 0.8270\n",
            "Epoch 538/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1639 - accuracy: 0.9403 - val_loss: 0.5275 - val_accuracy: 0.8414\n",
            "Epoch 539/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1684 - accuracy: 0.9383 - val_loss: 0.5371 - val_accuracy: 0.8379\n",
            "Epoch 540/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1536 - accuracy: 0.9486 - val_loss: 0.5242 - val_accuracy: 0.8328\n",
            "Epoch 541/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1678 - accuracy: 0.9380 - val_loss: 0.5380 - val_accuracy: 0.8356\n",
            "Epoch 542/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9403 - val_loss: 0.5413 - val_accuracy: 0.8362\n",
            "Epoch 543/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1614 - accuracy: 0.9457 - val_loss: 0.5332 - val_accuracy: 0.8328\n",
            "Epoch 544/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1593 - accuracy: 0.9440 - val_loss: 0.5188 - val_accuracy: 0.8420\n",
            "Epoch 545/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1581 - accuracy: 0.9463 - val_loss: 0.5358 - val_accuracy: 0.8356\n",
            "Epoch 546/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9403 - val_loss: 0.5396 - val_accuracy: 0.8339\n",
            "Epoch 547/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1565 - accuracy: 0.9463 - val_loss: 0.5373 - val_accuracy: 0.8391\n",
            "Epoch 548/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1512 - accuracy: 0.9460 - val_loss: 0.5226 - val_accuracy: 0.8449\n",
            "Epoch 549/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9372 - val_loss: 0.5216 - val_accuracy: 0.8472\n",
            "Epoch 550/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1500 - accuracy: 0.9488 - val_loss: 0.5289 - val_accuracy: 0.8339\n",
            "Epoch 551/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1592 - accuracy: 0.9463 - val_loss: 0.5284 - val_accuracy: 0.8351\n",
            "Epoch 552/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1520 - accuracy: 0.9460 - val_loss: 0.5430 - val_accuracy: 0.8293\n",
            "Epoch 553/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1431 - accuracy: 0.9517 - val_loss: 0.5310 - val_accuracy: 0.8403\n",
            "Epoch 554/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1485 - accuracy: 0.9434 - val_loss: 0.5300 - val_accuracy: 0.8328\n",
            "Epoch 555/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1641 - accuracy: 0.9440 - val_loss: 0.5269 - val_accuracy: 0.8345\n",
            "Epoch 556/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1524 - accuracy: 0.9451 - val_loss: 0.5418 - val_accuracy: 0.8374\n",
            "Epoch 557/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1644 - accuracy: 0.9389 - val_loss: 0.5260 - val_accuracy: 0.8351\n",
            "Epoch 558/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1514 - accuracy: 0.9497 - val_loss: 0.5657 - val_accuracy: 0.8339\n",
            "Epoch 559/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1601 - accuracy: 0.9414 - val_loss: 0.5356 - val_accuracy: 0.8322\n",
            "Epoch 560/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1509 - accuracy: 0.9468 - val_loss: 0.5379 - val_accuracy: 0.8362\n",
            "Epoch 561/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1483 - accuracy: 0.9474 - val_loss: 0.5313 - val_accuracy: 0.8316\n",
            "Epoch 562/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1487 - accuracy: 0.9474 - val_loss: 0.5253 - val_accuracy: 0.8454\n",
            "Epoch 563/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1404 - accuracy: 0.9463 - val_loss: 0.5325 - val_accuracy: 0.8420\n",
            "Epoch 564/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1436 - accuracy: 0.9494 - val_loss: 0.5558 - val_accuracy: 0.8241\n",
            "Epoch 565/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1545 - accuracy: 0.9449 - val_loss: 0.5324 - val_accuracy: 0.8351\n",
            "Epoch 566/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1457 - accuracy: 0.9517 - val_loss: 0.5261 - val_accuracy: 0.8385\n",
            "Epoch 567/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1517 - accuracy: 0.9497 - val_loss: 0.5530 - val_accuracy: 0.8356\n",
            "Epoch 568/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1523 - accuracy: 0.9446 - val_loss: 0.5269 - val_accuracy: 0.8443\n",
            "Epoch 569/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1474 - accuracy: 0.9474 - val_loss: 0.5248 - val_accuracy: 0.8397\n",
            "Epoch 570/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1589 - accuracy: 0.9406 - val_loss: 0.5344 - val_accuracy: 0.8368\n",
            "Epoch 571/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1529 - accuracy: 0.9477 - val_loss: 0.5131 - val_accuracy: 0.8426\n",
            "Epoch 572/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1481 - accuracy: 0.9508 - val_loss: 0.5397 - val_accuracy: 0.8431\n",
            "Epoch 573/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1425 - accuracy: 0.9525 - val_loss: 0.5292 - val_accuracy: 0.8351\n",
            "Epoch 574/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1528 - accuracy: 0.9468 - val_loss: 0.5105 - val_accuracy: 0.8408\n",
            "Epoch 575/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1517 - accuracy: 0.9503 - val_loss: 0.5204 - val_accuracy: 0.8356\n",
            "Epoch 576/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1544 - accuracy: 0.9474 - val_loss: 0.5179 - val_accuracy: 0.8454\n",
            "Epoch 577/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1506 - accuracy: 0.9503 - val_loss: 0.5413 - val_accuracy: 0.8414\n",
            "Epoch 578/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1558 - accuracy: 0.9429 - val_loss: 0.5318 - val_accuracy: 0.8437\n",
            "Epoch 579/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1421 - accuracy: 0.9517 - val_loss: 0.5328 - val_accuracy: 0.8385\n",
            "Epoch 580/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1422 - accuracy: 0.9511 - val_loss: 0.5480 - val_accuracy: 0.8304\n",
            "Epoch 581/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1548 - accuracy: 0.9443 - val_loss: 0.5491 - val_accuracy: 0.8293\n",
            "Epoch 582/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1431 - accuracy: 0.9508 - val_loss: 0.5297 - val_accuracy: 0.8478\n",
            "Epoch 583/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1332 - accuracy: 0.9514 - val_loss: 0.5608 - val_accuracy: 0.8356\n",
            "Epoch 584/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1460 - accuracy: 0.9511 - val_loss: 0.5366 - val_accuracy: 0.8356\n",
            "Epoch 585/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1574 - accuracy: 0.9454 - val_loss: 0.5128 - val_accuracy: 0.8379\n",
            "Epoch 586/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1452 - accuracy: 0.9494 - val_loss: 0.5393 - val_accuracy: 0.8385\n",
            "Epoch 587/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1373 - accuracy: 0.9525 - val_loss: 0.5399 - val_accuracy: 0.8379\n",
            "Epoch 588/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1365 - accuracy: 0.9574 - val_loss: 0.5345 - val_accuracy: 0.8310\n",
            "Epoch 589/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1460 - accuracy: 0.9497 - val_loss: 0.5311 - val_accuracy: 0.8397\n",
            "Epoch 590/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1525 - accuracy: 0.9463 - val_loss: 0.5507 - val_accuracy: 0.8374\n",
            "Epoch 591/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1493 - accuracy: 0.9474 - val_loss: 0.5393 - val_accuracy: 0.8449\n",
            "Epoch 592/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1507 - accuracy: 0.9511 - val_loss: 0.5466 - val_accuracy: 0.8379\n",
            "Epoch 593/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1466 - accuracy: 0.9480 - val_loss: 0.5429 - val_accuracy: 0.8287\n",
            "Epoch 594/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1410 - accuracy: 0.9505 - val_loss: 0.5398 - val_accuracy: 0.8322\n",
            "Epoch 595/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1462 - accuracy: 0.9497 - val_loss: 0.5592 - val_accuracy: 0.8379\n",
            "Epoch 596/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1378 - accuracy: 0.9497 - val_loss: 0.5218 - val_accuracy: 0.8460\n",
            "Epoch 597/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1478 - accuracy: 0.9503 - val_loss: 0.5535 - val_accuracy: 0.8385\n",
            "Epoch 598/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1317 - accuracy: 0.9559 - val_loss: 0.5493 - val_accuracy: 0.8374\n",
            "Epoch 599/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1296 - accuracy: 0.9599 - val_loss: 0.5436 - val_accuracy: 0.8420\n",
            "Epoch 600/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1467 - accuracy: 0.9434 - val_loss: 0.5617 - val_accuracy: 0.8454\n",
            "Epoch 601/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1321 - accuracy: 0.9548 - val_loss: 0.5635 - val_accuracy: 0.8431\n",
            "Epoch 602/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1489 - accuracy: 0.9505 - val_loss: 0.5374 - val_accuracy: 0.8454\n",
            "Epoch 603/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1371 - accuracy: 0.9503 - val_loss: 0.5554 - val_accuracy: 0.8362\n",
            "Epoch 604/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1475 - accuracy: 0.9446 - val_loss: 0.5478 - val_accuracy: 0.8362\n",
            "Epoch 605/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1331 - accuracy: 0.9551 - val_loss: 0.5385 - val_accuracy: 0.8391\n",
            "Epoch 606/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1396 - accuracy: 0.9497 - val_loss: 0.5463 - val_accuracy: 0.8408\n",
            "Epoch 607/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1378 - accuracy: 0.9497 - val_loss: 0.5468 - val_accuracy: 0.8368\n",
            "Epoch 608/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1367 - accuracy: 0.9562 - val_loss: 0.5275 - val_accuracy: 0.8414\n",
            "Epoch 609/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1359 - accuracy: 0.9534 - val_loss: 0.5479 - val_accuracy: 0.8362\n",
            "Epoch 610/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1487 - accuracy: 0.9477 - val_loss: 0.5477 - val_accuracy: 0.8322\n",
            "Epoch 611/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1429 - accuracy: 0.9497 - val_loss: 0.5592 - val_accuracy: 0.8454\n",
            "Epoch 612/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1369 - accuracy: 0.9508 - val_loss: 0.5467 - val_accuracy: 0.8391\n",
            "Epoch 613/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1471 - accuracy: 0.9508 - val_loss: 0.5350 - val_accuracy: 0.8403\n",
            "Epoch 614/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1449 - accuracy: 0.9463 - val_loss: 0.5570 - val_accuracy: 0.8368\n",
            "Epoch 615/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1346 - accuracy: 0.9522 - val_loss: 0.5587 - val_accuracy: 0.8293\n",
            "Epoch 616/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1302 - accuracy: 0.9542 - val_loss: 0.5545 - val_accuracy: 0.8426\n",
            "Epoch 617/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1297 - accuracy: 0.9540 - val_loss: 0.5469 - val_accuracy: 0.8437\n",
            "Epoch 618/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1344 - accuracy: 0.9505 - val_loss: 0.5439 - val_accuracy: 0.8443\n",
            "Epoch 619/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1305 - accuracy: 0.9517 - val_loss: 0.5647 - val_accuracy: 0.8299\n",
            "Epoch 620/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1316 - accuracy: 0.9525 - val_loss: 0.5432 - val_accuracy: 0.8391\n",
            "Epoch 621/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1367 - accuracy: 0.9497 - val_loss: 0.5564 - val_accuracy: 0.8339\n",
            "Epoch 622/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1359 - accuracy: 0.9500 - val_loss: 0.5447 - val_accuracy: 0.8379\n",
            "Epoch 623/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1350 - accuracy: 0.9545 - val_loss: 0.5473 - val_accuracy: 0.8339\n",
            "Epoch 624/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1235 - accuracy: 0.9574 - val_loss: 0.5434 - val_accuracy: 0.8385\n",
            "Epoch 625/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1328 - accuracy: 0.9520 - val_loss: 0.5552 - val_accuracy: 0.8339\n",
            "Epoch 626/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1316 - accuracy: 0.9554 - val_loss: 0.5227 - val_accuracy: 0.8460\n",
            "Epoch 627/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1313 - accuracy: 0.9548 - val_loss: 0.5621 - val_accuracy: 0.8310\n",
            "Epoch 628/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1344 - accuracy: 0.9494 - val_loss: 0.5652 - val_accuracy: 0.8379\n",
            "Epoch 629/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1257 - accuracy: 0.9613 - val_loss: 0.5547 - val_accuracy: 0.8379\n",
            "Epoch 630/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1393 - accuracy: 0.9508 - val_loss: 0.5745 - val_accuracy: 0.8362\n",
            "Epoch 631/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1267 - accuracy: 0.9585 - val_loss: 0.5532 - val_accuracy: 0.8374\n",
            "Epoch 632/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.9531 - val_loss: 0.5394 - val_accuracy: 0.8385\n",
            "Epoch 633/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1320 - accuracy: 0.9545 - val_loss: 0.5423 - val_accuracy: 0.8397\n",
            "Epoch 634/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1291 - accuracy: 0.9534 - val_loss: 0.5460 - val_accuracy: 0.8466\n",
            "Epoch 635/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1258 - accuracy: 0.9557 - val_loss: 0.5614 - val_accuracy: 0.8328\n",
            "Epoch 636/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1262 - accuracy: 0.9540 - val_loss: 0.5577 - val_accuracy: 0.8414\n",
            "Epoch 637/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1372 - accuracy: 0.9500 - val_loss: 0.5668 - val_accuracy: 0.8374\n",
            "Epoch 638/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1297 - accuracy: 0.9540 - val_loss: 0.5617 - val_accuracy: 0.8322\n",
            "Epoch 639/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1332 - accuracy: 0.9508 - val_loss: 0.5627 - val_accuracy: 0.8437\n",
            "Epoch 640/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1244 - accuracy: 0.9576 - val_loss: 0.5978 - val_accuracy: 0.8247\n",
            "Epoch 641/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1239 - accuracy: 0.9562 - val_loss: 0.5653 - val_accuracy: 0.8362\n",
            "Epoch 642/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1331 - accuracy: 0.9508 - val_loss: 0.5617 - val_accuracy: 0.8374\n",
            "Epoch 643/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1293 - accuracy: 0.9522 - val_loss: 0.5509 - val_accuracy: 0.8397\n",
            "Epoch 644/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1246 - accuracy: 0.9554 - val_loss: 0.5665 - val_accuracy: 0.8304\n",
            "Epoch 645/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1262 - accuracy: 0.9551 - val_loss: 0.5710 - val_accuracy: 0.8374\n",
            "Epoch 646/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1337 - accuracy: 0.9500 - val_loss: 0.5756 - val_accuracy: 0.8385\n",
            "Epoch 647/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1323 - accuracy: 0.9565 - val_loss: 0.5666 - val_accuracy: 0.8333\n",
            "Epoch 648/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1284 - accuracy: 0.9565 - val_loss: 0.5650 - val_accuracy: 0.8443\n",
            "Epoch 649/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1327 - accuracy: 0.9511 - val_loss: 0.5729 - val_accuracy: 0.8316\n",
            "Epoch 650/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1387 - accuracy: 0.9483 - val_loss: 0.5709 - val_accuracy: 0.8316\n",
            "Epoch 651/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1219 - accuracy: 0.9591 - val_loss: 0.5818 - val_accuracy: 0.8379\n",
            "Epoch 652/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1292 - accuracy: 0.9557 - val_loss: 0.5499 - val_accuracy: 0.8408\n",
            "Epoch 653/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1191 - accuracy: 0.9588 - val_loss: 0.5547 - val_accuracy: 0.8328\n",
            "Epoch 654/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9585 - val_loss: 0.5494 - val_accuracy: 0.8385\n",
            "Epoch 655/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1304 - accuracy: 0.9557 - val_loss: 0.5620 - val_accuracy: 0.8328\n",
            "Epoch 656/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1164 - accuracy: 0.9571 - val_loss: 0.5669 - val_accuracy: 0.8454\n",
            "Epoch 657/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1281 - accuracy: 0.9585 - val_loss: 0.5500 - val_accuracy: 0.8385\n",
            "Epoch 658/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9548 - val_loss: 0.5527 - val_accuracy: 0.8449\n",
            "Epoch 659/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9548 - val_loss: 0.5461 - val_accuracy: 0.8414\n",
            "Epoch 660/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1290 - accuracy: 0.9554 - val_loss: 0.5496 - val_accuracy: 0.8414\n",
            "Epoch 661/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1210 - accuracy: 0.9599 - val_loss: 0.5655 - val_accuracy: 0.8345\n",
            "Epoch 662/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1230 - accuracy: 0.9542 - val_loss: 0.5774 - val_accuracy: 0.8414\n",
            "Epoch 663/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1188 - accuracy: 0.9554 - val_loss: 0.5846 - val_accuracy: 0.8391\n",
            "Epoch 664/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1314 - accuracy: 0.9559 - val_loss: 0.5613 - val_accuracy: 0.8379\n",
            "Epoch 665/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1184 - accuracy: 0.9605 - val_loss: 0.5815 - val_accuracy: 0.8368\n",
            "Epoch 666/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1199 - accuracy: 0.9588 - val_loss: 0.5510 - val_accuracy: 0.8385\n",
            "Epoch 667/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1136 - accuracy: 0.9630 - val_loss: 0.5714 - val_accuracy: 0.8316\n",
            "Epoch 668/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1185 - accuracy: 0.9608 - val_loss: 0.5527 - val_accuracy: 0.8443\n",
            "Epoch 669/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1178 - accuracy: 0.9585 - val_loss: 0.5723 - val_accuracy: 0.8379\n",
            "Epoch 670/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1212 - accuracy: 0.9594 - val_loss: 0.5620 - val_accuracy: 0.8379\n",
            "Epoch 671/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1260 - accuracy: 0.9540 - val_loss: 0.5777 - val_accuracy: 0.8241\n",
            "Epoch 672/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1208 - accuracy: 0.9582 - val_loss: 0.5724 - val_accuracy: 0.8385\n",
            "Epoch 673/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1148 - accuracy: 0.9636 - val_loss: 0.5569 - val_accuracy: 0.8466\n",
            "Epoch 674/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1161 - accuracy: 0.9602 - val_loss: 0.5826 - val_accuracy: 0.8333\n",
            "Epoch 675/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1141 - accuracy: 0.9596 - val_loss: 0.5779 - val_accuracy: 0.8397\n",
            "Epoch 676/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1175 - accuracy: 0.9568 - val_loss: 0.5761 - val_accuracy: 0.8339\n",
            "Epoch 677/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9673 - val_loss: 0.5831 - val_accuracy: 0.8362\n",
            "Epoch 678/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1175 - accuracy: 0.9596 - val_loss: 0.5645 - val_accuracy: 0.8397\n",
            "Epoch 679/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1151 - accuracy: 0.9594 - val_loss: 0.5620 - val_accuracy: 0.8420\n",
            "Epoch 680/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1278 - accuracy: 0.9582 - val_loss: 0.5579 - val_accuracy: 0.8374\n",
            "Epoch 681/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.9602 - val_loss: 0.5541 - val_accuracy: 0.8368\n",
            "Epoch 682/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1118 - accuracy: 0.9625 - val_loss: 0.5801 - val_accuracy: 0.8351\n",
            "Epoch 683/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9591 - val_loss: 0.5557 - val_accuracy: 0.8385\n",
            "Epoch 684/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1121 - accuracy: 0.9591 - val_loss: 0.6053 - val_accuracy: 0.8264\n",
            "Epoch 685/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9630 - val_loss: 0.5575 - val_accuracy: 0.8391\n",
            "Epoch 686/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1176 - accuracy: 0.9562 - val_loss: 0.5707 - val_accuracy: 0.8385\n",
            "Epoch 687/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1160 - accuracy: 0.9613 - val_loss: 0.5555 - val_accuracy: 0.8449\n",
            "Epoch 688/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1185 - accuracy: 0.9574 - val_loss: 0.5741 - val_accuracy: 0.8437\n",
            "Epoch 689/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1167 - accuracy: 0.9574 - val_loss: 0.5585 - val_accuracy: 0.8385\n",
            "Epoch 690/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1205 - accuracy: 0.9554 - val_loss: 0.5658 - val_accuracy: 0.8431\n",
            "Epoch 691/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1269 - accuracy: 0.9520 - val_loss: 0.5698 - val_accuracy: 0.8374\n",
            "Epoch 692/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9565 - val_loss: 0.5764 - val_accuracy: 0.8339\n",
            "Epoch 693/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1159 - accuracy: 0.9667 - val_loss: 0.5910 - val_accuracy: 0.8362\n",
            "Epoch 694/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1118 - accuracy: 0.9625 - val_loss: 0.5958 - val_accuracy: 0.8276\n",
            "Epoch 695/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9619 - val_loss: 0.5653 - val_accuracy: 0.8391\n",
            "Epoch 696/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1164 - accuracy: 0.9596 - val_loss: 0.5714 - val_accuracy: 0.8356\n",
            "Epoch 697/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9648 - val_loss: 0.5878 - val_accuracy: 0.8293\n",
            "Epoch 698/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1141 - accuracy: 0.9622 - val_loss: 0.5597 - val_accuracy: 0.8322\n",
            "Epoch 699/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1181 - accuracy: 0.9633 - val_loss: 0.5711 - val_accuracy: 0.8345\n",
            "Epoch 700/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1194 - accuracy: 0.9557 - val_loss: 0.5789 - val_accuracy: 0.8351\n",
            "Epoch 701/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9650 - val_loss: 0.5634 - val_accuracy: 0.8437\n",
            "Epoch 702/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1163 - accuracy: 0.9582 - val_loss: 0.5885 - val_accuracy: 0.8362\n",
            "Epoch 703/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1188 - accuracy: 0.9602 - val_loss: 0.5857 - val_accuracy: 0.8362\n",
            "Epoch 704/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1046 - accuracy: 0.9613 - val_loss: 0.5911 - val_accuracy: 0.8310\n",
            "Epoch 705/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9622 - val_loss: 0.5814 - val_accuracy: 0.8374\n",
            "Epoch 706/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1164 - accuracy: 0.9559 - val_loss: 0.5873 - val_accuracy: 0.8368\n",
            "Epoch 707/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1124 - accuracy: 0.9596 - val_loss: 0.5805 - val_accuracy: 0.8420\n",
            "Epoch 708/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1140 - accuracy: 0.9639 - val_loss: 0.5631 - val_accuracy: 0.8328\n",
            "Epoch 709/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1029 - accuracy: 0.9639 - val_loss: 0.5883 - val_accuracy: 0.8391\n",
            "Epoch 710/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1155 - accuracy: 0.9574 - val_loss: 0.5708 - val_accuracy: 0.8351\n",
            "Epoch 711/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1180 - accuracy: 0.9588 - val_loss: 0.5731 - val_accuracy: 0.8391\n",
            "Epoch 712/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9642 - val_loss: 0.5610 - val_accuracy: 0.8403\n",
            "Epoch 713/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9633 - val_loss: 0.5841 - val_accuracy: 0.8351\n",
            "Epoch 714/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1033 - accuracy: 0.9642 - val_loss: 0.5944 - val_accuracy: 0.8304\n",
            "Epoch 715/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9639 - val_loss: 0.6018 - val_accuracy: 0.8293\n",
            "Epoch 716/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1208 - accuracy: 0.9585 - val_loss: 0.5718 - val_accuracy: 0.8322\n",
            "Epoch 717/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9628 - val_loss: 0.5893 - val_accuracy: 0.8368\n",
            "Epoch 718/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1036 - accuracy: 0.9622 - val_loss: 0.5864 - val_accuracy: 0.8310\n",
            "Epoch 719/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1163 - accuracy: 0.9639 - val_loss: 0.5876 - val_accuracy: 0.8304\n",
            "Epoch 720/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1151 - accuracy: 0.9622 - val_loss: 0.5725 - val_accuracy: 0.8374\n",
            "Epoch 721/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1091 - accuracy: 0.9625 - val_loss: 0.5727 - val_accuracy: 0.8391\n",
            "Epoch 722/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1140 - accuracy: 0.9613 - val_loss: 0.5621 - val_accuracy: 0.8379\n",
            "Epoch 723/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.9625 - val_loss: 0.5846 - val_accuracy: 0.8379\n",
            "Epoch 724/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9613 - val_loss: 0.5988 - val_accuracy: 0.8310\n",
            "Epoch 725/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1048 - accuracy: 0.9653 - val_loss: 0.6054 - val_accuracy: 0.8304\n",
            "Epoch 726/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9636 - val_loss: 0.6013 - val_accuracy: 0.8351\n",
            "Epoch 727/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.9611 - val_loss: 0.6265 - val_accuracy: 0.8299\n",
            "Epoch 728/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0962 - accuracy: 0.9676 - val_loss: 0.6002 - val_accuracy: 0.8316\n",
            "Epoch 729/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1153 - accuracy: 0.9568 - val_loss: 0.5985 - val_accuracy: 0.8328\n",
            "Epoch 730/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1078 - accuracy: 0.9662 - val_loss: 0.6004 - val_accuracy: 0.8368\n",
            "Epoch 731/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1097 - accuracy: 0.9628 - val_loss: 0.6013 - val_accuracy: 0.8328\n",
            "Epoch 732/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1130 - accuracy: 0.9591 - val_loss: 0.5904 - val_accuracy: 0.8374\n",
            "Epoch 733/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1066 - accuracy: 0.9636 - val_loss: 0.6434 - val_accuracy: 0.8345\n",
            "Epoch 734/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1167 - accuracy: 0.9630 - val_loss: 0.5862 - val_accuracy: 0.8385\n",
            "Epoch 735/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1067 - accuracy: 0.9611 - val_loss: 0.5686 - val_accuracy: 0.8374\n",
            "Epoch 736/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1013 - accuracy: 0.9630 - val_loss: 0.6052 - val_accuracy: 0.8333\n",
            "Epoch 737/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1044 - accuracy: 0.9648 - val_loss: 0.5802 - val_accuracy: 0.8304\n",
            "Epoch 738/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1056 - accuracy: 0.9625 - val_loss: 0.5774 - val_accuracy: 0.8333\n",
            "Epoch 739/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9645 - val_loss: 0.6047 - val_accuracy: 0.8333\n",
            "Epoch 740/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9642 - val_loss: 0.5920 - val_accuracy: 0.8426\n",
            "Epoch 741/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9630 - val_loss: 0.5775 - val_accuracy: 0.8379\n",
            "Epoch 742/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1062 - accuracy: 0.9636 - val_loss: 0.5926 - val_accuracy: 0.8339\n",
            "Epoch 743/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9642 - val_loss: 0.6006 - val_accuracy: 0.8362\n",
            "Epoch 744/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0993 - accuracy: 0.9676 - val_loss: 0.6149 - val_accuracy: 0.8374\n",
            "Epoch 745/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1098 - accuracy: 0.9619 - val_loss: 0.6019 - val_accuracy: 0.8345\n",
            "Epoch 746/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1156 - accuracy: 0.9613 - val_loss: 0.6050 - val_accuracy: 0.8293\n",
            "Epoch 747/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1086 - accuracy: 0.9625 - val_loss: 0.5854 - val_accuracy: 0.8356\n",
            "Epoch 748/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1052 - accuracy: 0.9611 - val_loss: 0.5908 - val_accuracy: 0.8304\n",
            "Epoch 749/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9630 - val_loss: 0.5841 - val_accuracy: 0.8414\n",
            "Epoch 750/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9648 - val_loss: 0.6142 - val_accuracy: 0.8379\n",
            "Epoch 751/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1067 - accuracy: 0.9659 - val_loss: 0.6073 - val_accuracy: 0.8339\n",
            "Epoch 752/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1032 - accuracy: 0.9645 - val_loss: 0.6115 - val_accuracy: 0.8270\n",
            "Epoch 753/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1069 - accuracy: 0.9596 - val_loss: 0.5979 - val_accuracy: 0.8328\n",
            "Epoch 754/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9687 - val_loss: 0.6190 - val_accuracy: 0.8356\n",
            "Epoch 755/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0997 - accuracy: 0.9684 - val_loss: 0.6098 - val_accuracy: 0.8328\n",
            "Epoch 756/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9645 - val_loss: 0.5924 - val_accuracy: 0.8362\n",
            "Epoch 757/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1130 - accuracy: 0.9591 - val_loss: 0.6042 - val_accuracy: 0.8322\n",
            "Epoch 758/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1075 - accuracy: 0.9625 - val_loss: 0.6155 - val_accuracy: 0.8304\n",
            "Epoch 759/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0971 - accuracy: 0.9665 - val_loss: 0.5980 - val_accuracy: 0.8391\n",
            "Epoch 760/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1062 - accuracy: 0.9630 - val_loss: 0.6143 - val_accuracy: 0.8276\n",
            "Epoch 761/1000\n",
            "220/220 [==============================] - 2s 7ms/step - loss: 0.1142 - accuracy: 0.9588 - val_loss: 0.6003 - val_accuracy: 0.8333\n",
            "Epoch 762/1000\n",
            "220/220 [==============================] - 2s 7ms/step - loss: 0.0891 - accuracy: 0.9693 - val_loss: 0.5950 - val_accuracy: 0.8351\n",
            "Epoch 763/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1091 - accuracy: 0.9596 - val_loss: 0.6163 - val_accuracy: 0.8379\n",
            "Epoch 764/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1013 - accuracy: 0.9653 - val_loss: 0.6278 - val_accuracy: 0.8316\n",
            "Epoch 765/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1008 - accuracy: 0.9653 - val_loss: 0.5899 - val_accuracy: 0.8426\n",
            "Epoch 766/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0940 - accuracy: 0.9667 - val_loss: 0.6176 - val_accuracy: 0.8391\n",
            "Epoch 767/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0995 - accuracy: 0.9696 - val_loss: 0.5985 - val_accuracy: 0.8403\n",
            "Epoch 768/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0904 - accuracy: 0.9665 - val_loss: 0.6344 - val_accuracy: 0.8351\n",
            "Epoch 769/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0962 - accuracy: 0.9682 - val_loss: 0.6002 - val_accuracy: 0.8310\n",
            "Epoch 770/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1021 - accuracy: 0.9622 - val_loss: 0.6234 - val_accuracy: 0.8322\n",
            "Epoch 771/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0912 - accuracy: 0.9667 - val_loss: 0.6198 - val_accuracy: 0.8328\n",
            "Epoch 772/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0932 - accuracy: 0.9662 - val_loss: 0.6261 - val_accuracy: 0.8304\n",
            "Epoch 773/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9670 - val_loss: 0.6541 - val_accuracy: 0.8333\n",
            "Epoch 774/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0929 - accuracy: 0.9687 - val_loss: 0.6034 - val_accuracy: 0.8310\n",
            "Epoch 775/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0961 - accuracy: 0.9670 - val_loss: 0.6052 - val_accuracy: 0.8304\n",
            "Epoch 776/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9650 - val_loss: 0.5958 - val_accuracy: 0.8408\n",
            "Epoch 777/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1039 - accuracy: 0.9633 - val_loss: 0.6467 - val_accuracy: 0.8230\n",
            "Epoch 778/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0923 - accuracy: 0.9662 - val_loss: 0.6082 - val_accuracy: 0.8316\n",
            "Epoch 779/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9690 - val_loss: 0.6162 - val_accuracy: 0.8304\n",
            "Epoch 780/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1067 - accuracy: 0.9630 - val_loss: 0.6194 - val_accuracy: 0.8437\n",
            "Epoch 781/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1003 - accuracy: 0.9687 - val_loss: 0.6117 - val_accuracy: 0.8454\n",
            "Epoch 782/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0985 - accuracy: 0.9639 - val_loss: 0.6181 - val_accuracy: 0.8345\n",
            "Epoch 783/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0923 - accuracy: 0.9679 - val_loss: 0.6226 - val_accuracy: 0.8316\n",
            "Epoch 784/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1013 - accuracy: 0.9690 - val_loss: 0.6149 - val_accuracy: 0.8328\n",
            "Epoch 785/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0885 - accuracy: 0.9676 - val_loss: 0.6305 - val_accuracy: 0.8379\n",
            "Epoch 786/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0937 - accuracy: 0.9684 - val_loss: 0.6256 - val_accuracy: 0.8345\n",
            "Epoch 787/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0872 - accuracy: 0.9693 - val_loss: 0.6174 - val_accuracy: 0.8356\n",
            "Epoch 788/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1064 - accuracy: 0.9613 - val_loss: 0.5957 - val_accuracy: 0.8322\n",
            "Epoch 789/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1045 - accuracy: 0.9639 - val_loss: 0.6176 - val_accuracy: 0.8403\n",
            "Epoch 790/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.1008 - accuracy: 0.9679 - val_loss: 0.6238 - val_accuracy: 0.8362\n",
            "Epoch 791/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0954 - accuracy: 0.9684 - val_loss: 0.5985 - val_accuracy: 0.8443\n",
            "Epoch 792/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0915 - accuracy: 0.9659 - val_loss: 0.6355 - val_accuracy: 0.8212\n",
            "Epoch 793/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0933 - accuracy: 0.9693 - val_loss: 0.6057 - val_accuracy: 0.8368\n",
            "Epoch 794/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0969 - accuracy: 0.9633 - val_loss: 0.6024 - val_accuracy: 0.8466\n",
            "Epoch 795/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0973 - accuracy: 0.9667 - val_loss: 0.6057 - val_accuracy: 0.8379\n",
            "Epoch 796/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0943 - accuracy: 0.9665 - val_loss: 0.6362 - val_accuracy: 0.8293\n",
            "Epoch 797/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9673 - val_loss: 0.6180 - val_accuracy: 0.8345\n",
            "Epoch 798/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1006 - accuracy: 0.9630 - val_loss: 0.6033 - val_accuracy: 0.8408\n",
            "Epoch 799/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0873 - accuracy: 0.9687 - val_loss: 0.6220 - val_accuracy: 0.8454\n",
            "Epoch 800/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9687 - val_loss: 0.5911 - val_accuracy: 0.8420\n",
            "Epoch 801/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0926 - accuracy: 0.9667 - val_loss: 0.6314 - val_accuracy: 0.8408\n",
            "Epoch 802/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0999 - accuracy: 0.9648 - val_loss: 0.6313 - val_accuracy: 0.8270\n",
            "Epoch 803/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0888 - accuracy: 0.9690 - val_loss: 0.6085 - val_accuracy: 0.8374\n",
            "Epoch 804/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0857 - accuracy: 0.9738 - val_loss: 0.6178 - val_accuracy: 0.8362\n",
            "Epoch 805/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9619 - val_loss: 0.6070 - val_accuracy: 0.8351\n",
            "Epoch 806/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1006 - accuracy: 0.9642 - val_loss: 0.6242 - val_accuracy: 0.8293\n",
            "Epoch 807/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0954 - accuracy: 0.9719 - val_loss: 0.6176 - val_accuracy: 0.8374\n",
            "Epoch 808/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0844 - accuracy: 0.9721 - val_loss: 0.6368 - val_accuracy: 0.8316\n",
            "Epoch 809/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0945 - accuracy: 0.9673 - val_loss: 0.6410 - val_accuracy: 0.8310\n",
            "Epoch 810/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0962 - accuracy: 0.9673 - val_loss: 0.6248 - val_accuracy: 0.8293\n",
            "Epoch 811/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9670 - val_loss: 0.6190 - val_accuracy: 0.8299\n",
            "Epoch 812/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9687 - val_loss: 0.5926 - val_accuracy: 0.8460\n",
            "Epoch 813/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0886 - accuracy: 0.9687 - val_loss: 0.6130 - val_accuracy: 0.8414\n",
            "Epoch 814/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0891 - accuracy: 0.9733 - val_loss: 0.6343 - val_accuracy: 0.8304\n",
            "Epoch 815/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0939 - accuracy: 0.9676 - val_loss: 0.6067 - val_accuracy: 0.8328\n",
            "Epoch 816/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0895 - accuracy: 0.9713 - val_loss: 0.5962 - val_accuracy: 0.8478\n",
            "Epoch 817/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0973 - accuracy: 0.9630 - val_loss: 0.6216 - val_accuracy: 0.8397\n",
            "Epoch 818/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0850 - accuracy: 0.9719 - val_loss: 0.6226 - val_accuracy: 0.8443\n",
            "Epoch 819/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0956 - accuracy: 0.9721 - val_loss: 0.6303 - val_accuracy: 0.8316\n",
            "Epoch 820/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0952 - accuracy: 0.9648 - val_loss: 0.6464 - val_accuracy: 0.8339\n",
            "Epoch 821/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0984 - accuracy: 0.9690 - val_loss: 0.6364 - val_accuracy: 0.8299\n",
            "Epoch 822/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9673 - val_loss: 0.6032 - val_accuracy: 0.8385\n",
            "Epoch 823/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0945 - accuracy: 0.9662 - val_loss: 0.6134 - val_accuracy: 0.8420\n",
            "Epoch 824/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0951 - accuracy: 0.9662 - val_loss: 0.6169 - val_accuracy: 0.8397\n",
            "Epoch 825/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0995 - accuracy: 0.9630 - val_loss: 0.6194 - val_accuracy: 0.8414\n",
            "Epoch 826/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9650 - val_loss: 0.6154 - val_accuracy: 0.8408\n",
            "Epoch 827/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0942 - accuracy: 0.9673 - val_loss: 0.6271 - val_accuracy: 0.8333\n",
            "Epoch 828/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9690 - val_loss: 0.6236 - val_accuracy: 0.8356\n",
            "Epoch 829/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9665 - val_loss: 0.6038 - val_accuracy: 0.8495\n",
            "Epoch 830/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0943 - accuracy: 0.9656 - val_loss: 0.6113 - val_accuracy: 0.8339\n",
            "Epoch 831/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0960 - accuracy: 0.9687 - val_loss: 0.6075 - val_accuracy: 0.8426\n",
            "Epoch 832/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0876 - accuracy: 0.9702 - val_loss: 0.6428 - val_accuracy: 0.8328\n",
            "Epoch 833/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0979 - accuracy: 0.9684 - val_loss: 0.6203 - val_accuracy: 0.8379\n",
            "Epoch 834/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0993 - accuracy: 0.9665 - val_loss: 0.6191 - val_accuracy: 0.8368\n",
            "Epoch 835/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0968 - accuracy: 0.9679 - val_loss: 0.6071 - val_accuracy: 0.8443\n",
            "Epoch 836/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0899 - accuracy: 0.9673 - val_loss: 0.6511 - val_accuracy: 0.8316\n",
            "Epoch 837/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0926 - accuracy: 0.9673 - val_loss: 0.6192 - val_accuracy: 0.8397\n",
            "Epoch 838/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0865 - accuracy: 0.9727 - val_loss: 0.6513 - val_accuracy: 0.8258\n",
            "Epoch 839/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0898 - accuracy: 0.9699 - val_loss: 0.6364 - val_accuracy: 0.8408\n",
            "Epoch 840/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0946 - accuracy: 0.9690 - val_loss: 0.6230 - val_accuracy: 0.8328\n",
            "Epoch 841/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9670 - val_loss: 0.6130 - val_accuracy: 0.8374\n",
            "Epoch 842/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0928 - accuracy: 0.9696 - val_loss: 0.6123 - val_accuracy: 0.8431\n",
            "Epoch 843/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0939 - accuracy: 0.9682 - val_loss: 0.6179 - val_accuracy: 0.8397\n",
            "Epoch 844/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9636 - val_loss: 0.6100 - val_accuracy: 0.8368\n",
            "Epoch 845/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0944 - accuracy: 0.9662 - val_loss: 0.6194 - val_accuracy: 0.8414\n",
            "Epoch 846/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0898 - accuracy: 0.9679 - val_loss: 0.6299 - val_accuracy: 0.8368\n",
            "Epoch 847/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0935 - accuracy: 0.9665 - val_loss: 0.6316 - val_accuracy: 0.8345\n",
            "Epoch 848/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9639 - val_loss: 0.6240 - val_accuracy: 0.8391\n",
            "Epoch 849/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0873 - accuracy: 0.9670 - val_loss: 0.6325 - val_accuracy: 0.8322\n",
            "Epoch 850/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0794 - accuracy: 0.9741 - val_loss: 0.6308 - val_accuracy: 0.8391\n",
            "Epoch 851/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0877 - accuracy: 0.9713 - val_loss: 0.6489 - val_accuracy: 0.8304\n",
            "Epoch 852/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0907 - accuracy: 0.9653 - val_loss: 0.6414 - val_accuracy: 0.8356\n",
            "Epoch 853/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0857 - accuracy: 0.9716 - val_loss: 0.6655 - val_accuracy: 0.8310\n",
            "Epoch 854/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0910 - accuracy: 0.9693 - val_loss: 0.6628 - val_accuracy: 0.8339\n",
            "Epoch 855/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0778 - accuracy: 0.9733 - val_loss: 0.6290 - val_accuracy: 0.8356\n",
            "Epoch 856/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0854 - accuracy: 0.9699 - val_loss: 0.6437 - val_accuracy: 0.8339\n",
            "Epoch 857/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9704 - val_loss: 0.6237 - val_accuracy: 0.8414\n",
            "Epoch 858/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0951 - accuracy: 0.9665 - val_loss: 0.6320 - val_accuracy: 0.8414\n",
            "Epoch 859/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0944 - accuracy: 0.9662 - val_loss: 0.6364 - val_accuracy: 0.8351\n",
            "Epoch 860/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0892 - accuracy: 0.9699 - val_loss: 0.6439 - val_accuracy: 0.8351\n",
            "Epoch 861/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0955 - accuracy: 0.9630 - val_loss: 0.6563 - val_accuracy: 0.8310\n",
            "Epoch 862/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0855 - accuracy: 0.9704 - val_loss: 0.6419 - val_accuracy: 0.8437\n",
            "Epoch 863/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0863 - accuracy: 0.9690 - val_loss: 0.6498 - val_accuracy: 0.8351\n",
            "Epoch 864/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0925 - accuracy: 0.9676 - val_loss: 0.6279 - val_accuracy: 0.8454\n",
            "Epoch 865/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0931 - accuracy: 0.9696 - val_loss: 0.6279 - val_accuracy: 0.8408\n",
            "Epoch 866/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0864 - accuracy: 0.9704 - val_loss: 0.6514 - val_accuracy: 0.8310\n",
            "Epoch 867/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0826 - accuracy: 0.9721 - val_loss: 0.6369 - val_accuracy: 0.8356\n",
            "Epoch 868/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0826 - accuracy: 0.9724 - val_loss: 0.6400 - val_accuracy: 0.8414\n",
            "Epoch 869/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0913 - accuracy: 0.9702 - val_loss: 0.6429 - val_accuracy: 0.8362\n",
            "Epoch 870/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0779 - accuracy: 0.9741 - val_loss: 0.6310 - val_accuracy: 0.8449\n",
            "Epoch 871/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0848 - accuracy: 0.9699 - val_loss: 0.6345 - val_accuracy: 0.8374\n",
            "Epoch 872/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0838 - accuracy: 0.9696 - val_loss: 0.6375 - val_accuracy: 0.8293\n",
            "Epoch 873/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0887 - accuracy: 0.9696 - val_loss: 0.6413 - val_accuracy: 0.8408\n",
            "Epoch 874/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0895 - accuracy: 0.9699 - val_loss: 0.6259 - val_accuracy: 0.8420\n",
            "Epoch 875/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9665 - val_loss: 0.6379 - val_accuracy: 0.8339\n",
            "Epoch 876/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0890 - accuracy: 0.9673 - val_loss: 0.6293 - val_accuracy: 0.8403\n",
            "Epoch 877/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0777 - accuracy: 0.9753 - val_loss: 0.6341 - val_accuracy: 0.8403\n",
            "Epoch 878/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0786 - accuracy: 0.9719 - val_loss: 0.6390 - val_accuracy: 0.8408\n",
            "Epoch 879/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9753 - val_loss: 0.6583 - val_accuracy: 0.8316\n",
            "Epoch 880/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0844 - accuracy: 0.9707 - val_loss: 0.6594 - val_accuracy: 0.8408\n",
            "Epoch 881/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0957 - accuracy: 0.9696 - val_loss: 0.6543 - val_accuracy: 0.8299\n",
            "Epoch 882/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0782 - accuracy: 0.9738 - val_loss: 0.6496 - val_accuracy: 0.8345\n",
            "Epoch 883/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0745 - accuracy: 0.9741 - val_loss: 0.6539 - val_accuracy: 0.8454\n",
            "Epoch 884/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0762 - accuracy: 0.9741 - val_loss: 0.6412 - val_accuracy: 0.8379\n",
            "Epoch 885/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0853 - accuracy: 0.9741 - val_loss: 0.6475 - val_accuracy: 0.8356\n",
            "Epoch 886/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0766 - accuracy: 0.9707 - val_loss: 0.6677 - val_accuracy: 0.8322\n",
            "Epoch 887/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0778 - accuracy: 0.9719 - val_loss: 0.6379 - val_accuracy: 0.8408\n",
            "Epoch 888/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0878 - accuracy: 0.9687 - val_loss: 0.6496 - val_accuracy: 0.8374\n",
            "Epoch 889/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0792 - accuracy: 0.9721 - val_loss: 0.6188 - val_accuracy: 0.8420\n",
            "Epoch 890/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0863 - accuracy: 0.9693 - val_loss: 0.6706 - val_accuracy: 0.8385\n",
            "Epoch 891/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0791 - accuracy: 0.9741 - val_loss: 0.6620 - val_accuracy: 0.8391\n",
            "Epoch 892/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0795 - accuracy: 0.9744 - val_loss: 0.6495 - val_accuracy: 0.8391\n",
            "Epoch 893/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0824 - accuracy: 0.9719 - val_loss: 0.6298 - val_accuracy: 0.8460\n",
            "Epoch 894/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0824 - accuracy: 0.9710 - val_loss: 0.6472 - val_accuracy: 0.8385\n",
            "Epoch 895/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0825 - accuracy: 0.9690 - val_loss: 0.6527 - val_accuracy: 0.8391\n",
            "Epoch 896/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0854 - accuracy: 0.9690 - val_loss: 0.6310 - val_accuracy: 0.8449\n",
            "Epoch 897/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0794 - accuracy: 0.9758 - val_loss: 0.6809 - val_accuracy: 0.8333\n",
            "Epoch 898/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9733 - val_loss: 0.6689 - val_accuracy: 0.8368\n",
            "Epoch 899/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9716 - val_loss: 0.6531 - val_accuracy: 0.8374\n",
            "Epoch 900/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0804 - accuracy: 0.9719 - val_loss: 0.6546 - val_accuracy: 0.8356\n",
            "Epoch 901/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0821 - accuracy: 0.9707 - val_loss: 0.6635 - val_accuracy: 0.8374\n",
            "Epoch 902/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0847 - accuracy: 0.9710 - val_loss: 0.6421 - val_accuracy: 0.8333\n",
            "Epoch 903/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0841 - accuracy: 0.9758 - val_loss: 0.6692 - val_accuracy: 0.8328\n",
            "Epoch 904/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0805 - accuracy: 0.9744 - val_loss: 0.6346 - val_accuracy: 0.8403\n",
            "Epoch 905/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0953 - accuracy: 0.9699 - val_loss: 0.6387 - val_accuracy: 0.8368\n",
            "Epoch 906/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0808 - accuracy: 0.9721 - val_loss: 0.6793 - val_accuracy: 0.8351\n",
            "Epoch 907/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0782 - accuracy: 0.9733 - val_loss: 0.6642 - val_accuracy: 0.8345\n",
            "Epoch 908/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0824 - accuracy: 0.9704 - val_loss: 0.6536 - val_accuracy: 0.8356\n",
            "Epoch 909/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9727 - val_loss: 0.6324 - val_accuracy: 0.8385\n",
            "Epoch 910/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0740 - accuracy: 0.9747 - val_loss: 0.6513 - val_accuracy: 0.8333\n",
            "Epoch 911/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0790 - accuracy: 0.9744 - val_loss: 0.6437 - val_accuracy: 0.8322\n",
            "Epoch 912/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0795 - accuracy: 0.9724 - val_loss: 0.6457 - val_accuracy: 0.8316\n",
            "Epoch 913/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0829 - accuracy: 0.9716 - val_loss: 0.6417 - val_accuracy: 0.8460\n",
            "Epoch 914/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0870 - accuracy: 0.9699 - val_loss: 0.6466 - val_accuracy: 0.8351\n",
            "Epoch 915/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0794 - accuracy: 0.9719 - val_loss: 0.6495 - val_accuracy: 0.8397\n",
            "Epoch 916/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0760 - accuracy: 0.9747 - val_loss: 0.6506 - val_accuracy: 0.8362\n",
            "Epoch 917/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0819 - accuracy: 0.9687 - val_loss: 0.6432 - val_accuracy: 0.8426\n",
            "Epoch 918/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0794 - accuracy: 0.9747 - val_loss: 0.6807 - val_accuracy: 0.8322\n",
            "Epoch 919/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0748 - accuracy: 0.9730 - val_loss: 0.6452 - val_accuracy: 0.8356\n",
            "Epoch 920/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0753 - accuracy: 0.9761 - val_loss: 0.6723 - val_accuracy: 0.8333\n",
            "Epoch 921/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0785 - accuracy: 0.9721 - val_loss: 0.6799 - val_accuracy: 0.8322\n",
            "Epoch 922/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0815 - accuracy: 0.9721 - val_loss: 0.6610 - val_accuracy: 0.8397\n",
            "Epoch 923/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9684 - val_loss: 0.6639 - val_accuracy: 0.8374\n",
            "Epoch 924/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0895 - accuracy: 0.9659 - val_loss: 0.6591 - val_accuracy: 0.8293\n",
            "Epoch 925/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0831 - accuracy: 0.9721 - val_loss: 0.6382 - val_accuracy: 0.8403\n",
            "Epoch 926/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0704 - accuracy: 0.9770 - val_loss: 0.6516 - val_accuracy: 0.8443\n",
            "Epoch 927/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0744 - accuracy: 0.9716 - val_loss: 0.6787 - val_accuracy: 0.8385\n",
            "Epoch 928/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0794 - accuracy: 0.9736 - val_loss: 0.6444 - val_accuracy: 0.8408\n",
            "Epoch 929/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0684 - accuracy: 0.9747 - val_loss: 0.6684 - val_accuracy: 0.8414\n",
            "Epoch 930/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0832 - accuracy: 0.9721 - val_loss: 0.6676 - val_accuracy: 0.8385\n",
            "Epoch 931/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0761 - accuracy: 0.9741 - val_loss: 0.6486 - val_accuracy: 0.8397\n",
            "Epoch 932/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0740 - accuracy: 0.9756 - val_loss: 0.6611 - val_accuracy: 0.8391\n",
            "Epoch 933/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0723 - accuracy: 0.9764 - val_loss: 0.6667 - val_accuracy: 0.8356\n",
            "Epoch 934/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9736 - val_loss: 0.6530 - val_accuracy: 0.8374\n",
            "Epoch 935/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0732 - accuracy: 0.9753 - val_loss: 0.6359 - val_accuracy: 0.8460\n",
            "Epoch 936/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0672 - accuracy: 0.9770 - val_loss: 0.6724 - val_accuracy: 0.8316\n",
            "Epoch 937/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9744 - val_loss: 0.6605 - val_accuracy: 0.8385\n",
            "Epoch 938/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0837 - accuracy: 0.9724 - val_loss: 0.6436 - val_accuracy: 0.8374\n",
            "Epoch 939/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9747 - val_loss: 0.6573 - val_accuracy: 0.8374\n",
            "Epoch 940/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0712 - accuracy: 0.9736 - val_loss: 0.6596 - val_accuracy: 0.8356\n",
            "Epoch 941/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0783 - accuracy: 0.9747 - val_loss: 0.6438 - val_accuracy: 0.8501\n",
            "Epoch 942/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9716 - val_loss: 0.6944 - val_accuracy: 0.8287\n",
            "Epoch 943/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0766 - accuracy: 0.9721 - val_loss: 0.6922 - val_accuracy: 0.8374\n",
            "Epoch 944/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0753 - accuracy: 0.9761 - val_loss: 0.6803 - val_accuracy: 0.8397\n",
            "Epoch 945/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0797 - accuracy: 0.9690 - val_loss: 0.6525 - val_accuracy: 0.8449\n",
            "Epoch 946/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0727 - accuracy: 0.9719 - val_loss: 0.6507 - val_accuracy: 0.8379\n",
            "Epoch 947/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0730 - accuracy: 0.9756 - val_loss: 0.6719 - val_accuracy: 0.8270\n",
            "Epoch 948/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0771 - accuracy: 0.9738 - val_loss: 0.6553 - val_accuracy: 0.8397\n",
            "Epoch 949/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0770 - accuracy: 0.9738 - val_loss: 0.6970 - val_accuracy: 0.8322\n",
            "Epoch 950/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0803 - accuracy: 0.9724 - val_loss: 0.6628 - val_accuracy: 0.8362\n",
            "Epoch 951/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0691 - accuracy: 0.9738 - val_loss: 0.6682 - val_accuracy: 0.8362\n",
            "Epoch 952/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0683 - accuracy: 0.9741 - val_loss: 0.6825 - val_accuracy: 0.8368\n",
            "Epoch 953/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0818 - accuracy: 0.9736 - val_loss: 0.6697 - val_accuracy: 0.8356\n",
            "Epoch 954/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0696 - accuracy: 0.9750 - val_loss: 0.6765 - val_accuracy: 0.8322\n",
            "Epoch 955/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0731 - accuracy: 0.9753 - val_loss: 0.6634 - val_accuracy: 0.8362\n",
            "Epoch 956/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0788 - accuracy: 0.9721 - val_loss: 0.7035 - val_accuracy: 0.8281\n",
            "Epoch 957/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0752 - accuracy: 0.9773 - val_loss: 0.6754 - val_accuracy: 0.8379\n",
            "Epoch 958/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0825 - accuracy: 0.9756 - val_loss: 0.6749 - val_accuracy: 0.8379\n",
            "Epoch 959/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0723 - accuracy: 0.9761 - val_loss: 0.6944 - val_accuracy: 0.8397\n",
            "Epoch 960/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0659 - accuracy: 0.9758 - val_loss: 0.6633 - val_accuracy: 0.8368\n",
            "Epoch 961/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0846 - accuracy: 0.9704 - val_loss: 0.6733 - val_accuracy: 0.8420\n",
            "Epoch 962/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0780 - accuracy: 0.9738 - val_loss: 0.6764 - val_accuracy: 0.8293\n",
            "Epoch 963/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9713 - val_loss: 0.6689 - val_accuracy: 0.8345\n",
            "Epoch 964/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0735 - accuracy: 0.9767 - val_loss: 0.6951 - val_accuracy: 0.8253\n",
            "Epoch 965/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0786 - accuracy: 0.9707 - val_loss: 0.6797 - val_accuracy: 0.8391\n",
            "Epoch 966/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0702 - accuracy: 0.9770 - val_loss: 0.6748 - val_accuracy: 0.8426\n",
            "Epoch 967/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9753 - val_loss: 0.6774 - val_accuracy: 0.8339\n",
            "Epoch 968/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0737 - accuracy: 0.9750 - val_loss: 0.6648 - val_accuracy: 0.8391\n",
            "Epoch 969/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0974 - accuracy: 0.9662 - val_loss: 0.6785 - val_accuracy: 0.8368\n",
            "Epoch 970/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0787 - accuracy: 0.9756 - val_loss: 0.6593 - val_accuracy: 0.8437\n",
            "Epoch 971/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0650 - accuracy: 0.9750 - val_loss: 0.6831 - val_accuracy: 0.8356\n",
            "Epoch 972/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0701 - accuracy: 0.9770 - val_loss: 0.6563 - val_accuracy: 0.8379\n",
            "Epoch 973/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0741 - accuracy: 0.9750 - val_loss: 0.6945 - val_accuracy: 0.8379\n",
            "Epoch 974/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0702 - accuracy: 0.9756 - val_loss: 0.7022 - val_accuracy: 0.8345\n",
            "Epoch 975/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0786 - accuracy: 0.9716 - val_loss: 0.6740 - val_accuracy: 0.8374\n",
            "Epoch 976/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0722 - accuracy: 0.9741 - val_loss: 0.6729 - val_accuracy: 0.8356\n",
            "Epoch 977/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0662 - accuracy: 0.9756 - val_loss: 0.6795 - val_accuracy: 0.8379\n",
            "Epoch 978/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0787 - accuracy: 0.9733 - val_loss: 0.6942 - val_accuracy: 0.8345\n",
            "Epoch 979/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0735 - accuracy: 0.9747 - val_loss: 0.6850 - val_accuracy: 0.8316\n",
            "Epoch 980/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0820 - accuracy: 0.9710 - val_loss: 0.6819 - val_accuracy: 0.8368\n",
            "Epoch 981/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0779 - accuracy: 0.9719 - val_loss: 0.6669 - val_accuracy: 0.8460\n",
            "Epoch 982/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0674 - accuracy: 0.9792 - val_loss: 0.6958 - val_accuracy: 0.8304\n",
            "Epoch 983/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0670 - accuracy: 0.9795 - val_loss: 0.6822 - val_accuracy: 0.8408\n",
            "Epoch 984/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0657 - accuracy: 0.9761 - val_loss: 0.6989 - val_accuracy: 0.8310\n",
            "Epoch 985/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0864 - accuracy: 0.9699 - val_loss: 0.6619 - val_accuracy: 0.8408\n",
            "Epoch 986/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0825 - accuracy: 0.9736 - val_loss: 0.7011 - val_accuracy: 0.8264\n",
            "Epoch 987/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0830 - accuracy: 0.9738 - val_loss: 0.6781 - val_accuracy: 0.8339\n",
            "Epoch 988/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0660 - accuracy: 0.9787 - val_loss: 0.6674 - val_accuracy: 0.8379\n",
            "Epoch 989/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0753 - accuracy: 0.9710 - val_loss: 0.6618 - val_accuracy: 0.8460\n",
            "Epoch 990/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0774 - accuracy: 0.9707 - val_loss: 0.6853 - val_accuracy: 0.8322\n",
            "Epoch 991/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0636 - accuracy: 0.9795 - val_loss: 0.6780 - val_accuracy: 0.8356\n",
            "Epoch 992/1000\n",
            "220/220 [==============================] - 2s 8ms/step - loss: 0.0670 - accuracy: 0.9738 - val_loss: 0.6988 - val_accuracy: 0.8339\n",
            "Epoch 993/1000\n",
            "220/220 [==============================] - 2s 7ms/step - loss: 0.0698 - accuracy: 0.9764 - val_loss: 0.6964 - val_accuracy: 0.8374\n",
            "Epoch 994/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0663 - accuracy: 0.9781 - val_loss: 0.6880 - val_accuracy: 0.8391\n",
            "Epoch 995/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0721 - accuracy: 0.9778 - val_loss: 0.6826 - val_accuracy: 0.8356\n",
            "Epoch 996/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0849 - accuracy: 0.9741 - val_loss: 0.6666 - val_accuracy: 0.8431\n",
            "Epoch 997/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0780 - accuracy: 0.9727 - val_loss: 0.6512 - val_accuracy: 0.8483\n",
            "Epoch 998/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0680 - accuracy: 0.9773 - val_loss: 0.6883 - val_accuracy: 0.8420\n",
            "Epoch 999/1000\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 0.0671 - accuracy: 0.9758 - val_loss: 0.6774 - val_accuracy: 0.8385\n",
            "Epoch 1000/1000\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.0676 - accuracy: 0.9801 - val_loss: 0.6788 - val_accuracy: 0.8379\n"
          ]
        }
      ],
      "source": [
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000, validation_data=(x_testcnn, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFytY6LDzgJ0"
      },
      "source": [
        "**Let's plot the loss:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "TFz4ClZov9gZ",
        "outputId": "9ab6613e-4aa4-41d3-dbc8-a0b675703740"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf1W7LgP2DA5"
      },
      "source": [
        "**And now let's plot the accuracy:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8yyFBt7ASPUe",
        "outputId": "af03bc11-e84b-4dbe-cdf8-25e0fab4051c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaZONl1mD8XD"
      },
      "source": [
        "Let's now create a classification report to review the f1-score of the model per class.\n",
        "To do so, we have to:\n",
        "- Create a variable predictions that will contain the model.predict_classes outcome\n",
        "- Convert our y_test (array of strings with our classes) to an array of int called new_Ytest, otherwise it will not be comparable to the predictions by the classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO25uIL-9vqx"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_testcnn) \n",
        "classes_x = np.argmax(predictions,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i06grlBBSrn",
        "outputId": "110031fe-f207-4504-f1ff-f07c2d847aa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 6, 4, ..., 3, 0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "classes_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUHshx93CM_6",
        "outputId": "2e324530-5659-470a-d693-9667aa6b3cc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 7, 0, ..., 3, 0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMxojpvWCxOs"
      },
      "outputs": [],
      "source": [
        "new_Ytest = y_test.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W07EQaC8DE6i",
        "outputId": "7cfd4e3b-0a8c-4879-a476-22d3afad9193"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 7, 0, ..., 3, 0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "new_Ytest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW2XHdTtEedk"
      },
      "source": [
        "Okay, now we can display the classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfVSRmMu96rC",
        "outputId": "87ecf2e0-6566-47a4-8ac6-8ff28d133c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89       189\n",
            "           1       0.79      0.71      0.75       124\n",
            "           2       0.83      0.82      0.82       243\n",
            "           3       0.86      0.78      0.82       239\n",
            "           4       0.84      0.90      0.86       267\n",
            "           5       0.82      0.80      0.81       264\n",
            "           6       0.81      0.86      0.83       202\n",
            "           7       0.89      0.89      0.89       206\n",
            "\n",
            "    accuracy                           0.84      1734\n",
            "   macro avg       0.84      0.83      0.83      1734\n",
            "weighted avg       0.84      0.84      0.84      1734\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(new_Ytest, classes_x)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu1S5IowfSDG"
      },
      "source": [
        "And now, the confusion matrix: it will show us the misclassified samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdy09SCEd7Cl",
        "outputId": "18ea0837-d566-4c06-8d2a-0f3ca73bc5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[173   4   1   8   1   0   2   0]\n",
            " [  8  88  11   2   5   5   5   0]\n",
            " [  1   5 199   4  11  13   6   4]\n",
            " [ 13   9   5 186   4  14   4   4]\n",
            " [  0   2   6   0 239   6  12   2]\n",
            " [  2   4   9  13  12 211   7   6]\n",
            " [  0   0   5   4   8   4 174   7]\n",
            " [  3   0   4   0   6   4   6 183]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "matrix = confusion_matrix(new_Ytest, classes_x)\n",
        "print (matrix)\n",
        "\n",
        "# 0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ySPOyHxkZ3"
      },
      "source": [
        "# Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5kRmoD-sdHj",
        "outputId": "63e1e8fc-9354-4cda-810d-a93993237746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved trained model at /content/drive/MyDrive/Emotion/Emotion_Voice_Detection_Model.h5 \n"
          ]
        }
      ],
      "source": [
        "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
        "save_dir = '/content/drive/MyDrive/Emotion'\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNUiznKNwUtJ"
      },
      "source": [
        "# Reloading the model to test it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4oAv6Kx8RBE",
        "outputId": "d1da24d9-5d9a-4fde-9a46-54cb3b568dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (None, 40, 128)           768       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 5, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 5, 128)            82048     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 5, 128)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 5, 128)            0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 640)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 5128      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,944\n",
            "Trainable params: 87,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "loaded_model = keras.models.load_model('/content/drive/MyDrive/Emotion/Emotion_Voice_Detection_Model.h5')\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHtPzc0Y8hfZ"
      },
      "source": [
        "# Checking the accuracy of the loaded model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUi-Zjuf8hDB",
        "outputId": "39f31ad8-9e49-4e2e-c2be-a463aae09f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.8379\n",
            "Restored model, accuracy: 83.79%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = loaded_model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pXH3y7S9A1N"
      },
      "source": [
        "# Thank you for your attention! To be continued.."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}